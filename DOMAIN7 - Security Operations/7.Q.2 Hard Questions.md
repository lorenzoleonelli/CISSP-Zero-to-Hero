## 7.Q.2 Hard Questions ##

1. As a security engineer, you are tasked with making the active IDS function as an Intrusion Prevention System (IPS) while following best practices outlined in NIST SP 800-94. According to NIST SP 800-94, which of the following is a key requirement for making an active IDS function as an IPS?

A. It must be installed in the DMZ

B. It must be properly hardened

C. It must fail securely

D. It must be in line with the traffic

<details> <summary>Show answer</summary>

✅ Correct Answer: D. It must be in line with the traffic

An IDS can act as an IPS only if it is placed in-line with network traffic, allowing it to actively block or modify packets in real time. According to NIST SP 800-94, in-line placement is the defining requirement that transforms a passive detection system into an active prevention system.

IDS vs. IPS Placement:

IDS → Out-of-band (monitors traffic passively)

IPS → In-line (analyzes and blocks malicious traffic immediately)

Incorrect Answers:

❌ A. It must be installed in the DMZ
Placement in the DMZ may enhance protection for public-facing systems, but it is not required for IDS-to-IPS conversion.

❌ B. It must be properly hardened
Hardening improves overall system security but does not determine IDS or IPS functionality.

❌ C. It must fail securely
Fail-secure mechanisms (fail-open or fail-closed) improve resilience but are not the key factor in enabling IPS behavior.

</details>

---

2. You are a security analyst conducting a risk assessment for a newly discovered vulnerability in your company's software. As part of your evaluation, you use the Common Vulnerability Scoring System (CVSS) to determine the severity and potential impact of the vulnerability. CVSS provides various metrics to assess risk, but which of the following is NOT an area of concern in a CVSS assessment?

A. Base metrics for qualities intrinsic to a vulnerability

B. Environmental metrics for vulnerabilities that depend on a particular implementation or environment

C. Temporal metrics for characteristics that evolve over the lifetime of a vulnerability

D. International compliance metrics related to the vulnerability

<details> <summary>Show answer</summary>

✅ Correct Answer: D. International compliance metrics related to the vulnerability

Explanation:
CVSS does not evaluate compliance or regulatory factors. It focuses purely on the technical severity of a vulnerability, not on whether an organization meets international standards like GDPR, ISO 27001, or NIST.

CVSS Metric Groups:

Base Metrics: Intrinsic properties of a vulnerability (e.g., exploitability, impact).

Temporal Metrics: Factors that change over time (e.g., exploit availability, patch maturity).

Environmental Metrics: Contextual adjustments for a specific organization (e.g., existing controls, asset value).

Incorrect Answers:
❌ A. Base metrics — Measure inherent characteristics of a vulnerability.
❌ B. Environmental metrics — Adapt severity based on local conditions.
❌ C. Temporal metrics — Reflect time-dependent characteristics like available exploits.

</details>

---

3. A junior administrator is tasked with installing an application on a Windows server. The application requires specific privileges to run properly. Which of the following account types should the administrator use to ensure the application runs with the necessary privileges while minimizing security risks?

A. Local Admin Account

B. Service Account

C. Domain Admin Account

D. Application Admin Account

<details> <summary>Show answer</summary>

Correct Answer:

✅ B. Service Account

Explanation:
Service accounts are designed to run applications or services with the minimal privileges needed to access required system resources. This approach limits security risks while ensuring the application functions properly.

Incorrect Answers:

❌ A. Local Admin Account:
Provides broad privileges on a single machine, which is over-privileged and increases security risks.

❌ C. Domain Admin Account:
Has unrestricted domain-wide privileges, making it unsuitable and risky for running an application.

❌ D. Application Admin Account:
A less clearly defined term and may not be set up with proper limited privileges, making it a less reliable choice.

</details>

---

4. An IT forensic investigator has been tasked with preserving evidence from a suspect’s hard drive as part of an ongoing investigation. To ensure the data remains unaltered and can later be analyzed accurately, the investigator needs to create a forensic image of the drive. Which tool would be most helpful in ensuring the integrity of the data while making this copy?

A. Hashing tool

B. Data diode

C. Write blocker

D. Cleanroom

<details> <summary>Show answer</summary>

Correct Answer:

✅ C. Write blocker

Explanation:
A write blocker allows data to be read from a storage device without risking any modifications. This ensures the original evidence remains unaltered during forensic imaging, preserving its integrity for later analysis.

Incorrect Answers:

❌ A. Hashing tool:
Used to verify data integrity by generating hash values, but does not prevent changes during imaging.

❌ D. Cleanroom:
A controlled environment for physical repairs on damaged drives, not necessary for imaging functional drives.

❌ B. Data diode:
A one-way data transfer device used in secure environments, unrelated to forensic imaging.

</details>

---

5. After finalizing a Service Level Agreement (SLA) with one of your service providers, how do you plan to internally communicate and share the responsibilities to your team to ensure support for the contractual SLA? (Choose the best answer)

A. Using OLAs (Operational Level Agreements)

B. Using frameworks

C. Sharing Contractual Accountability and Liabilities

D. Through Policies

<details> <summary>Show answer</summary>

Correct Answer:

✅ A. Using OLAs (Operational Level Agreements)

Explanation:
OLAs are internal agreements that define operational responsibilities and relationships between teams. They help translate SLA requirements into clear, actionable tasks within the organization, ensuring smooth delivery and accountability.

Incorrect Answers:

❌ B. Using frameworks:
Too broad and nonspecific for communicating immediate team responsibilities related to SLAs.

❌ C. Sharing Contractual Accountability and Liabilities:
Important at a higher organizational level but lacks detailed operational guidance for daily team activities.

❌ D. Through Policies:
Policies provide high-level guidelines but usually don’t cover the specific, detailed responsibilities needed for SLA support.

</details>

---

6. Your organization is reviewing its security posture against email-related threats. Which of the following types of attacks can use emails as a threat vector? (Choose all that apply)

A. Mail bombing

B. Phishing

C. Man-in-the-Middle (MITM)

D. Distributed Denial of Service (DDoS)

<details> <summary>Show answer</summary>

Correct Answers:

✅ A. Mail bombing
✅ B. Phishing
✅ C. Man-in-the-Middle (MITM)
✅ D. Distributed Denial of Service (DDoS)

Explanation:

Phishing: Fraudulent emails deceive recipients into revealing sensitive information or executing malicious actions.

Mail bombing: Flooding an email server or recipient with excessive emails, causing disruption or denial of service.

Man-in-the-Middle (MITM): Emails can be used to trick users into connecting to malicious networks or reveal credentials; unencrypted emails can be intercepted or altered.

Distributed Denial of Service (DDoS): Malicious emails can distribute malware that enlists devices into botnets, which then perform DDoS attacks.

</details>

---

7. An IT investigator has been assigned to discover how confidential company documents ended up on a public file-sharing platform. There’s a strong suspicion that an internal employee transferred the data over the network to an external server, but this theory still needs verification. Which tool or method would help confirm if this hypothesis is correct?

A. File Integrity Monitoring

B. Cryptographic Data Shredding

C. Data Loss Prevention (DLP)

D. Network Log Analysis

<details> <summary>Show answer</summary>

Correct Answers:

✅ C. Data Loss Prevention (DLP)
✅ D. Network Log Analysis

Explanation:

Data Loss Prevention (DLP): Specifically designed to monitor and control sensitive data movement, DLP tools can detect and alert on unauthorized transfers to external servers, helping confirm insider exfiltration attempts.

Network Log Analysis: By examining network traffic logs, investigators can identify suspicious transmissions to external or unauthorized servers, correlating timing and destinations to the suspected data leak.

Incorrect Answers:
❌ Cryptographic Data Shredding: This securely deletes data but does not provide monitoring or detection capabilities for data exfiltration.
❌ File Integrity Monitoring (FIM): Focuses on detecting unauthorized file changes, not tracking file transfers or movement, thus less useful for confirming data exfiltration events.

</details>

---

8. Your organization is setting up a SIEM (Security Information and Event Management) system, but there are certain factors that could prevent it from being fully effective. Which of the following would completely undermine the usefulness of your SIEM implementation? (Choose two)

A. Absence of event deduplication rules

B. Lack of an inventory of monitored nodes

C. Failure to use NTP (Network Time Protocol) on all monitored nodes

D. Lack of event correlation rules

<details> <summary>Show answer</summary>

Correct Answers:

✅ B. Lack of an inventory of monitored nodes
✅ C. Failure to use NTP (Network Time Protocol) on all monitored nodes

Explanation:

Without a complete and accurate inventory of all monitored nodes, the SIEM cannot collect logs from all critical systems, leaving blind spots in monitoring and missing potential security incidents.

Without NTP to synchronize time across devices, event timestamps will be inconsistent, making correlation and incident investigation unreliable or impossible.

Incorrect Answers:

❌ A. Absence of event deduplication rules: While deduplication improves efficiency by reducing noise, its absence does not completely negate SIEM functionality. The SIEM can still collect and process events, though it may be noisier.

❌ D. Lack of event correlation rules: Correlation rules enhance detection by linking related events, but their absence reduces effectiveness rather than nullifying SIEM functionality. Basic logging and alerting can still occur.

</details>

---

9. Your organization is working to maintain an up-to-date Business Continuity Plan (BCP). When should the BCP be updated to ensure it is effective and relevant? (Choose all that apply)

A. During a security incident

B. Regularly at specified time intervals (once or twice a year)

C. When a system or service changes

D. Before an audit

<details> <summary>Show answer</summary>

Correct Answers:

✅ B. Regularly at specified time intervals (once or twice a year)
✅ C. When a system or service changes

Explanation:

Regular updates ensure the BCP stays current with organizational changes and emerging risks, maintaining its effectiveness over time.

Any significant changes in systems or services can impact business operations and recovery strategies, so the BCP must reflect these updates to remain accurate.

Incorrect Answers:

❌ D. Before an audit
While it’s good to have the BCP updated before audits, relying solely on audits to update the plan means it may be outdated during normal operations. Continuous maintenance is better.

❌ A. During a security incident
Updating the BCP during an incident distracts from response efforts. Instead, update the plan after resolution and review lessons learned to improve it.

</details>

---

10. You are tasked with designing a Disaster Recovery Plan (DRP) for your organization's primary data center, which processes critical business operations. Which of the following should be your first consideration?

A. Choosing the correct power supply solution for the backup Data Center

B. Evaluating the ALE of natural disasters for the backup data center

C. Ensuring the Disaster Recovery Plan integrates seamlessly with the Business Continuity Plan (BCP)

D. Assessing the Annualized Loss Expectancy (ALE) of natural disasters for the primary data center

<details> <summary>Show answer</summary>

Correct Answer:

✅ B. Evaluating the ALE of natural disasters for the backup data center

Explanation:
Annualized Loss Expectancy (ALE) measures the expected financial loss due to specific risks over a year. When designing a DRP, it’s critical to first evaluate the risks to the backup data center since the DRP’s success depends on having a resilient secondary site. Understanding the backup site’s exposure to natural disasters helps ensure it can reliably restore operations during an incident.

Incorrect Answers:

❌ A. Choosing the correct power supply solution for the backup data center:
Power supply is important but is an implementation detail that comes after risk evaluation. You must first select and assess the backup site’s risk before addressing infrastructure components like power.

❌ D. Assessing the ALE of natural disasters for the primary data center:
While useful for overall risk understanding, the DRP focuses on recovery capabilities via the backup site. The ALE of the primary site is less relevant to DRP design than the backup site’s resilience.

❌ C. Ensuring the Disaster Recovery Plan integrates seamlessly with the Business Continuity Plan (BCP):
Integration is important but only after ensuring the backup site is capable. Without a reliable backup data center, integration with BCP won’t be effective.

</details>

---

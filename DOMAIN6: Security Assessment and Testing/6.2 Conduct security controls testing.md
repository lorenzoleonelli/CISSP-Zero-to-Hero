## 6.2.1 Vulnerability Assessment ##

In cybersecurity, vulnerabilities must be clearly described so that both humans and automated systems can communicate about them. Several naming standards and scoring systems exist to help standardize vulnerability data across the industry.

**SCAP (Security Content Automation Protocol)** is a framework developed by NIST (National Institute of Standards and Technology) to automate the process of checking systems for vulnerabilities and configuration issues. SCAP combines multiple standards under one umbrella so tools can speak the same language.

:link: [Security Content Automation Protocol SCAP.](https://csrc.nist.gov/projects/security-content-automation-protocol)

**CVE (Common Vulnerabilities and Exposures)** assigns a unique ID to every known vulnerability. For example: CVE-2023-12345.
This makes it easy to reference the same issue across vendors, tools, and reports. CVE entries contain a short description, a publication date, and links to advisories and patches.

:link: [https://cve.mitre.org/](https://www.cve.org/)

These standards help automate vulnerability discovery, analysis, and reporting, making security assessments faster, more reliable, and easier to maintain:

| Standard | Purpose | Key Features | Example / Use Case |
|----------|----------|--------------|---------------------|
| **CVSS** (Common Vulnerability Scoring System) | Assigns a severity score (0.0–10.0) to vulnerabilities | Considers exploitability, confidentiality, integrity, availability, and environmental factors | A vulnerability with CVSS 9.8 is prioritized for immediate patching |
| **CCE** (Common Configuration Enumeration) | Identifies insecure system configurations | Provides unique IDs for misconfigurations instead of software bugs | Example: Windows Server allows weak password hashes |
| **CPE** (Common Platform Enumeration) | Standardized naming for software, hardware, and OS | Ensures scanners match the correct software version to vulnerabilities | “cpe:2.3:a:microsoft:office:2019” used in a vulnerability database |
| **XCCDF** (eXtensible Configuration Checklist Description Format) | Defines structured security checklists and rules | Provides pass/fail criteria for compliance assessments | An XCCDF file specifies Linux hardening rules (e.g., disable root SSH login) |
| **OVAL** (Open Vulnerability and Assessment Language) | Machine-readable vulnerability definitions | Scanners use OVAL tests to check system compliance automatically | Detecting if a patch is missing by running OVAL-defined checks |

A **vulnerability scan** inspects systems for known security weaknesses. These scans compare system data against vulnerability databases and known exploit conditions. Tools like Nessus, OpenVAS, Qualys, or Nexpose perform these scans and typically check for:
- Missing patches
- Default or weak configurations
- Exposed ports and services
- Known software flaws (linked to CVEs)

Vulnerability scanning can be done with or without credentials:
- Unauthenticated scan: limited to external inspection (open ports, service banners).
- Authenticated scan: allows deeper inspection of patch levels, file permissions, and configurations.

Before doing a vulnerability scan, security teams often run a **discovery scan** to find out what devices and systems exist on the network, because you can’t protect what you don’t know about. Discovery scans tell you which machines are online, what services are running, and which ports are open, which helps you make a complete inventory. When you scan a network, you also learn about the status of ports, which are like digital doors that let data in and out of a system. Ports can be open, which means the door is wide open and a service is ready to accept connections; closed, which means the door is shut but the system is reachable; filtered, which means the firewall is hiding the port so you can’t easily tell if it’s open or closed; or unfiltered, which means the port is reachable but the scanner can’t determine its exact state. Understanding these port states helps you see which systems are exposed to the internet or the internal network, and where attackers might focus their efforts. When it comes to scanning for vulnerabilities, you can focus on the whole network or specialize by type of system. For example, network vulnerability scans are used to check servers, routers, printers, and computers to see if there are weak spots like old software, unpatched services, misconfigurations, or exposed administration interfaces. 

If the focus is on websites and web applications, you would use a **web vulnerability scanner**, which looks for problems like SQL injection, where an attacker can trick the website into running malicious database commands, or cross-site scripting, where attackers inject code into pages that other users see. Web scanners also check if sensitive data is protected with encryption, if session tokens are secure, and if security headers are missing. 

**Databases** also have their own types of security scans, because they often store sensitive business or customer information. A database scan looks for things like weak passwords, insecure settings, missing updates, or excessive user permissions that allow people to access more data than they should. 

After scanning is done and all potential problems are found, the real work begins — which is managing the vulnerabilities. This is called the vulnerability management process, and it helps you handle problems in a way that is organized and reduces risk. First, you must keep a complete and up-to-date list of all devices, servers, and systems in your organization, because if you miss something, you won’t be scanning it or fixing it, and attackers might find it first. Then, when vulnerabilities are identified by your scanner, each finding must be carefully reviewed to make sure it’s a real issue and not a false alarm. Some vulnerabilities look dangerous but are not exploitable on your system due to specific configurations or other defenses. After confirming the real risks, the next step is to prioritize them, because not all problems are equally urgent. Security teams usually rely on the CVSS score, the importance of the affected system, and whether the vulnerability is known to be exploited in real-world attacks. Critical vulnerabilities on systems exposed to the internet are usually fixed first, especially if the system stores customer data or controls important business functions. Once you know which vulnerabilities need fixing, the next step is remediation, which means applying patches, changing settings, disabling risky services, or putting extra protections in place. If the vulnerability can’t be fixed immediately, you might reduce the risk temporarily by blocking network access or isolating the affected system. After the fix is applied, you should always check to make sure the problem is really solved, either by running another scan or testing manually. Finally, everything should be recorded in reports, so the organization can keep track of which systems were affected, how long it took to fix them, and what the overall risk level is. These reports also help show auditors and regulators that the company takes security seriously. Over time, security teams look for patterns and try to improve their processes, so fewer vulnerabilities slip through the cracks in the future. This whole cycle — from discovering systems, scanning for problems, fixing them, verifying the fixes, and reporting results — repeats continuously, because new vulnerabilities are discovered all the time, and old systems can fall out of compliance as software ages or new configurations are deployed. Security assessments are a core part of making sure your systems are protected against both known and unknown threats, and when done regularly and carefully, they greatly reduce the risk of data breaches, downtime, and costly cyberattacks.

| Step | Description | Key Points |
|------|-------------|------------|
| **1. Asset Inventory** | Maintain an up-to-date list of devices, servers, and systems. | Missing assets = unscanned, unprotected, exploitable by attackers. |
| **2. Vulnerability Identification** | Use scanners to find potential problems. | Review carefully to confirm real issues and filter false positives. |
| **3. Risk Validation** | Assess whether vulnerabilities are truly exploitable in your environment. | Some may look severe but aren’t exploitable due to configs/defenses. |
| **4. Prioritization** | Rank vulnerabilities by urgency. | Consider CVSS score, criticality of the system, and known exploits. |
| **5. Remediation** | Fix vulnerabilities by patching, changing configs, disabling risky services, or adding protections. | If not possible immediately, apply temporary risk reduction (e.g., block network access). |
| **6. Verification** | Confirm that fixes worked. | Re-scan or manually test to ensure vulnerabilities are resolved. |
| **7. Reporting** | Document vulnerabilities, fixes, timelines, and risk levels. | Reports show accountability and compliance for auditors/regulators. |
| **8. Continuous Improvement** | Analyze trends and refine processes. | Goal: reduce recurring issues, improve speed/effectiveness. |
| **Ongoing Cycle** | Repeat scanning and fixing continuously. | New vulnerabilities appear constantly; old systems can drift out of compliance. |

### Open Questions ###

1. Why do we need naming standards like CVE when dealing with cybersecurity vulnerabilities?

<details> <summary>Show answer</summary> Naming standards like CVE allow everyone — vendors, researchers, security tools — to talk about the same vulnerability using a common label. This avoids confusion and ensures consistency across reports, patches, and alerts. </details>

2. What is the purpose of the CVSS score when evaluating vulnerabilities?

<details> <summary>Show answer</summary> The CVSS score helps security teams understand how severe a vulnerability is, and decide how urgently it needs to be fixed. High scores mean the vulnerability is easier to exploit or causes more damage. </details>

3. How does CPE help scanners during a vulnerability assessment?

<details> <summary>Show answer</summary> CPE makes sure that scanners match the correct vulnerability to the exact software, hardware, or operating system version. This reduces false alarms and ensures only relevant issues are reported. </details>

4. What makes SCAP important in security automation?

<details> <summary>Show answer</summary> SCAP helps different security tools use the same rules and formats to automatically check systems for vulnerabilities and misconfigurations, making security checks faster and more reliable. </details>

5. Why is OVAL useful when scanning for vulnerabilities?

<details> <summary>Show answer</summary> OVAL turns vulnerability descriptions into machine-readable checks, so automated tools can scan systems without human interpretation, improving speed and consistency. </details>

6. What does an XCCDF file do in a security assessment?

<details> <summary>Show answer</summary> XCCDF defines security rules in a structured format that tools can follow, helping automate the process of verifying system configurations and hardening servers against attacks. </details>

7. Why are vulnerability scans usually combined with discovery scans?

<details> <summary>Show answer</summary> Discovery scans help identify all the devices and services on a network, making sure that vulnerability scans don’t miss systems that are unknown or hidden. </details>

8. What can you learn by checking the state of a network port during a scan?

<details> <summary>Show answer</summary> By checking port states, you can learn if a service is running and reachable (open), blocked (filtered), disabled (closed), or uncertain (unfiltered). This helps detect exposure points for potential attacks. </details>

9. How does web vulnerability scanning differ from network vulnerability scanning?

<details> <summary>Show answer</summary> Web vulnerability scanning focuses on flaws in websites and apps, like SQL injection or broken encryption, while network vulnerability scanning targets devices, services, and configurations on a broader network level. </details>

10. Why is vulnerability management more than just scanning?

<details> <summary>Show answer</summary> Vulnerability management includes identifying, validating, prioritizing, fixing, and verifying vulnerabilities. This structured approach prevents attackers from exploiting known issues and helps maintain long-term security. </details>

---

## 6.2.2 Penetration testing (e.g., red, blue, and/or purple team exercises) ##

Penetration testing, often called **pentesting**, is a security testing method where ethical hackers simulate real-world attacks on systems, networks, applications, or even physical locations to find weaknesses before malicious attackers do. The goal of penetration testing is to identify vulnerabilities in a controlled and safe way, so that companies can fix them before they are exploited. Pentesters act like real attackers, but with permission from the company, and usually follow a carefully agreed plan to avoid damage or disruption.

There are different types of penetration testing, depending on how much information the tester is given before the test begins. The three most common types are white box, gray box, and black box testing. 

| Test Type | Knowledge Provided | Simulates | Strengths | Limitations | Typical Use Cases |
|-----------|--------------------|-----------|-----------|-------------|-------------------|
| **White box testing** | Full knowledge — architecture diagrams, source code, config files, sometimes admin access. | Insider attack or attacker who already has extensive internal info. | Very deep analysis; finds design flaws, insecure configs, and code-level issues; efficient at locating logic bugs. | Less realistic for external attacks; may miss issues an external attacker would exploit through discovery. | Code reviews, secure SDLC checks, deep application or system audits. |
| **Gray box testing** | Partial knowledge — some credentials or network details, but no full source/config access. | Attacker with limited insider access (e.g., employee or compromised account) trying to escalate or move laterally. | Good balance of realism and depth; can find privilege escalation and lateral-movement issues; more focused than black box. | May still miss deep code-level problems; depends on the quality of partial info provided. | Web app tests with user-level access, internal web services, employee-facing systems. |
| **Black box testing** | No internal knowledge — tester uses public info, open ports, and visible services only. | External attacker approaching from the internet or public networks. | Very realistic for external threats; tests discovery and external attack surface; useful for public-facing assets. | May miss deep internal or code-level vulnerabilities; can be time-consuming to discover complex issues. | External penetration tests for websites, mail servers, VPNs, and perimeter services. |

Before a penetration test starts, both the customer and the pentesting team agree on a clear set of **rules of engagement**. These rules are essential to avoid misunderstanding, legal issues, or accidental disruption of business operations. The rules define what systems are in scope, what testing techniques are allowed, what times the tests can take place, what to do if a critical vulnerability is found, and how the results will be reported. Common pentesting rules also include instructions for handling sensitive data and communication during and after the test.

Pentesting is usually performed in structured phases. 

The first phase is **Planning and Reconnaissance**, where the tester gathers information about the target from public sources, like domain names, DNS records, website content, employee emails, or social media. 
In some cases, this step uses both passive and active scanning. 

The second phase is **Scanning**, which involves using automated tools or manual techniques to map the network, identify open ports, services, and vulnerabilities. 

The third phase is **Gaining Access**, where the tester tries to exploit weaknesses to enter the system. Once access is obtained.

The fourth phase, **Maintaining Access**, simulates how long an attacker could stay undetected by setting up backdoors or creating fake accounts. 

The fifth phase is **Analysis and Reporting**, where the tester documents everything: which vulnerabilities were found, how they were exploited, what level of access was gained, and recommendations on how to fix the problems.

While most people think of penetration testing as something that happens on computers and networks, there is also physical **penetration testing**. In this type of test, security professionals attempt to physically breach the security of buildings, offices, or data centers. The goal is to test the effectiveness of physical controls such as locks, security guards, surveillance cameras, access badges, alarms, and visitor procedures. Physical pentesting can include techniques like lock picking, tailgating (following an authorized person into a secured area), bypassing access controls, social engineering (like pretending to be a delivery person), and even planting hardware devices like rogue Wi-Fi access points or USB drop attacks. Physical penetration testing helps organizations understand how secure their premises are against both casual and targeted intrusions, and whether their staff is following proper security protocols.

:necktie: Overall, penetration testing is a critical part of modern cybersecurity programs. Whether the focus is digital systems, web applications, wireless networks, cloud environments, or physical access, the objective is always the same: simulate an attack in a safe and controlled way to detect weak points before someone malicious does. Penetration tests should always end with a clear, structured report that explains not just the technical problems found, but also the business risk and the recommended fix for each issue. This way the organization can prioritize remediation and improve its security posture in a continuous cycle of assessment, fixing, and retesting.

The terms Red Team, Blue Team, and Purple Team describe roles and exercises designed to improve an organization’s defense against real-world attacks. Each “team” has a specific function in the security testing process, and together they create a cycle of attack, defense, and learning that helps organizations strengthen their security posture.

| Team | Role | Main Activities | Tools & Techniques | Goal | Collaboration Style |
|------|------|----------------|--------------------|------|---------------------|
| **Red Team** | Acts like an advanced attacker, simulating real-world cyberattacks against systems, networks, apps, and people. | Intelligence gathering, exploiting vulnerabilities, social engineering, phishing, bypassing physical security, planting rogue devices, pivoting between systems. | Exploit frameworks, phishing kits, malware, rogue devices, stealth techniques. | Test how well the organization can detect and respond to advanced, realistic attacks without warning. | Works covertly, usually without SOC/IT staff knowledge. |
| **Blue Team** | Defensive security team monitoring and protecting systems in real time. | Log analysis, intrusion detection, monitoring SIEM alerts, stopping attacks, containing threats, investigating incidents, hardening systems, patching, training users. | IDS/IPS, SIEM platforms, endpoint protection, threat intelligence, monitoring tools. | Reduce attack surface, detect intrusions early, respond effectively, and improve defenses over time. | Works continuously, reacts to Red Team attacks when they happen. |
| **Purple Team** | Bridge between Red and Blue Teams to improve collaboration and effectiveness. | Documenting attacks step by step, explaining techniques, showing Blue Team how attacks worked, suggesting detection & prevention improvements. | Reporting tools, knowledge-sharing platforms, simulations, collaborative exercises. | Accelerate learning, strengthen detection & prevention, ensure Red-Blue collaboration. | Works side by side with both teams, often more of an approach than a separate team. |

:necktie: Red, Blue, and Purple teaming exercises are extremely valuable because they move security from theory to practice. A company might have the best security policies on paper, but until a Red Team tests them and a Blue Team defends against them, no one knows how those defenses will hold up under real attack conditions. Red Teams show what an attacker can do, Blue Teams show how well the defenses hold up, and Purple Teams make sure everyone learns and improves after every test. Together, these teams form a continuous loop of improvement that helps organizations prepare for real cyber threats.

### Open Questions ###

1. What is the main goal of penetration testing?  
<details>  
  <summary>Show answer</summary>  
The main goal of penetration testing is to safely simulate real-world cyberattacks to find and fix vulnerabilities before malicious attackers exploit them.  
</details>  

2. Why do companies allow ethical hackers to perform penetration tests on their systems?  
<details>  
  <summary>Show answer</summary>  
Companies allow ethical hackers to perform penetration tests to uncover weaknesses in a controlled environment and strengthen their defenses.  
</details>  

3. What are the three most common types of penetration testing based on knowledge shared with the tester?  
<details>  
  <summary>Show answer</summary>  
The three most common types of penetration testing are white box, gray box, and black box testing.  
</details>  

4. In white box testing, what kind of information is typically shared with the pentester?  
<details>  
  <summary>Show answer</summary>  
In white box testing, the pentester is given full knowledge of the target system, including source code, architecture diagrams, and configuration files.  
</details>  

5. What real-world scenario does gray box testing aim to simulate?  
<details>  
  <summary>Show answer</summary>  
Gray box testing simulates the scenario where an attacker has limited insider knowledge or access, similar to a compromised employee account or partial system breach.  
</details>  

6. Why is black box testing useful for testing public-facing systems?  
<details>  
  <summary>Show answer</summary>  
Black box testing is useful for assessing the security of public-facing systems, because it mimics how an external attacker would approach the target without any prior knowledge.  
</details>  

7. What is the purpose of defining “rules of engagement” before starting a penetration test?  
<details>  
  <summary>Show answer</summary>  
Defining rules of engagement helps ensure that both the tester and the organization are clear on what is allowed, what systems are in scope, and how to handle risks or discoveries during the test.  
</details>  

8. What happens during the Planning and Reconnaissance phase of a penetration test?  
<details>  
  <summary>Show answer</summary>  
During the Planning and Reconnaissance phase, testers gather public information about the target, such as domain names, open services, and employee details.  
</details>  

9. What does the Scanning phase of a penetration test focus on?  
<details>  
  <summary>Show answer</summary>  
The Scanning phase focuses on identifying open ports, active services, and potential vulnerabilities using automated tools and manual techniques.  
</details>  

10. What is the Gaining Access phase designed to test in a penetration test?  
<details>  
  <summary>Show answer</summary>  
The Gaining Access phase tests whether the identified vulnerabilities can be exploited to enter or control the target system.  
</details>  

---

## 6.2.3 Log Reviews ##

A **log review** is the process of systematically examining log files to identify abnormal patterns, unauthorized actions, misconfigurations, or security incidents. Since logs record nearly every important event in a digital environment, they often provide the earliest indicators of compromise or technical failure.

Regular log reviews allow organizations to spot signs of trouble such as repeated failed logins, privilege escalation, system crashes, unexpected software installations, network anomalies, and other signs of compromise. Log reviews can be manual — where a security analyst inspects logs directly — or automated using specialized tools. Reviewing logs is a fundamental task for security and compliance, and is required by many standards such as ISO 27001, PCI-DSS, HIPAA, and NIST frameworks.

A **Security Information and Event Management (SIEM)** system is a platform designed to automatically collect, store, analyze, and correlate log data from multiple systems in real time. SIEM systems help detect security incidents much faster than manual log review, and they often trigger automated alerts if suspicious patterns are identified.

SIEMs aggregate logs from servers, firewalls, routers, IDS/IPS devices, cloud services, and endpoint security tools, then normalize the data into a consistent format. Once the data is centralized, the SIEM engine applies correlation rules, machine learning, or threat intelligence feeds to identify events that require immediate attention.

:bulb: Popular SIEM systems like Splunk, IBM QRadar, ArcSight, and Microsoft Sentinel allow security teams to automate detection, generate security dashboards, and assist with forensic analysis after incidents. SIEM platforms also play an essential role in compliance, helping produce audit-ready reports that demonstrate security event monitoring is active and effective.

**NetFlow** is a network protocol developed by Cisco that collects and records information about IP traffic flows traversing network interfaces. Unlike simple log files, which record discrete events, NetFlow data summarizes entire conversations between network endpoints. This makes it ideal for network visibility, capacity planning, anomaly detection, and forensic analysis.

NetFlow records include details like source IP, destination IP, source port, destination port, protocol type, packet count, byte count, and timestamps for flow start and end. This allows security teams to answer critical questions such as:
- Who is communicating with whom?
- When did the communication happen?
- How much data was transferred?
- Which protocols and ports were used?

When integrated with SIEM systems or log management platforms, NetFlow enhances situational awareness and helps detect threats like data exfiltration, port scanning, or lateral movement inside a compromised network.

**Log management** refers to the full lifecycle of log data: generation, collection, centralization, storage, analysis, retention, and secure disposal. Without proper log management, even the most advanced security tools will fail to deliver meaningful results because the raw data will be incomplete, inconsistent, or missing altogether.

A strong log management strategy includes:
- Defining which devices and systems must send logs.
- Securing log transmission (using encrypted channels).
- Centralizing logs in a secure repository.
- Structuring retention policies (how long logs must be kept).
- Implementing access control on log files.
- Regularly reviewing logs for anomalies.
- Automating alerting and analysis when possible.

:bulb: Modern log management systems like ELK Stack (Elasticsearch, Logstash, Kibana), Graylog, and cloud-native solutions like AWS CloudWatch or Azure Monitor help scale log collection and analysis, even for large or distributed systems.

### Open Questions ###

1. What is the primary goal of performing a log review in an organization?

<details> <summary>Show answer</summary> The primary goal of a log review is to systematically examine log files to detect abnormal patterns, unauthorized actions, misconfigurations, or security incidents early, before they escalate into larger problems. </details>

2. How does a SIEM system improve the efficiency of security monitoring compared to manual log reviews?

<details> <summary>Show answer</summary> A SIEM system improves security monitoring by automatically collecting, normalizing, analyzing, and correlating logs from multiple sources in real time, helping to detect incidents faster and triggering alerts when suspicious patterns are identified. </details>

3. What kind of network information does NetFlow provide that traditional log files might not capture?

<details> <summary>Show answer</summary> NetFlow provides detailed information about network traffic flows, including source and destination IP addresses, ports, protocols, data volume, and timestamps — helping security teams understand communication patterns, detect anomalies, and perform network forensics. </details>

4. Why is log management considered essential for both security monitoring and compliance?

<details> <summary>Show answer</summary> Log management ensures that log data is consistently collected, securely stored, properly retained, and regularly analyzed, which is critical for detecting security incidents, troubleshooting issues, and meeting compliance requirements such as ISO 27001, PCI-DSS, HIPAA, and NIST. </details>

5. List at least three best practices that should be included in a strong log management strategy.

<details> <summary>Show answer</summary> Best practices in log management include: securing log transmission, centralizing logs in a secure repository, applying retention policies, enforcing access controls on logs, and using automation for log review and anomaly detection. </details>

---

## 6.2.4 Synthetic transactions/benchmarks ##

A synthetic transaction is a testing technique used to check if a system, website, or application is working properly — even when no real users are currently using it. 

:brain: Synthetic transactions are fake or automated actions that simulate what a real person would do, like logging in, filling out a form, making a payment, or clicking a button.

These "fake" actions are created by developers or security teams and run automatically at regular times, or from different locations, to see if the system responds correctly. The goal is to spot problems before real users notice them and before security risks appear.

For example for an online banking website. A synthetic transaction could try to log in with a test account every five minutes. If the login page doesn’t load, or the response time is too slow, the monitoring system will send an alert so the technical team can check for issues — even if no customer has complained yet.

Besides checking performance, synthetic transactions are useful for cybersecurity too. They can help detect if something has gone wrong in the system due to a security problem, like:

- If a website has been defaced or hacked.
- If a login process is no longer working due to an attack.
- If a database is being blocked or slowed down by malicious traffic.
- If a service is "pretending" to be healthy, but the backend is actually broken or under attack.

By running synthetic transactions 24/7, an organization can notice unexpected changes in behavior that might be caused by security incidents. This helps reduce the time between when a problem happens and when it's detected (called Mean Time To Detect — MTTD).

Synthetic transactions are also helpful for:

- Baseline monitoring: knowing what "normal" looks like, so you can quickly spot abnormal activity.
- Testing under safe conditions: without needing real customers to be involved.
- Geographical coverage: you can run synthetic tests from different cities or countries to see if global users experience the same performance and security.

**Real User Monitoring (RUM)** is a different but equally important technique. While synthetic transactions simulate fake users, RUM tracks real users as they interact with your website, system, or application in real time.

Every time a real customer logs in, clicks, loads a page, or uses a service, RUM quietly collects data about their experience:

- Was the page fast or slow to load?
- Did any errors appear?
- Which part of the world is the user connecting from?
- What device or browser was the user using?

RUM helps organizations understand how real people are experiencing their system — not just under test conditions, but in day-to-day use, under real-world traffic and situations. This is valuable for both security and performance.

From a security perspective, RUM can:

1. Show unusual patterns, such as a single user making thousands of requests in a short time.
2. Detect suspicious activities like bots trying to scrape content or break into accounts.
3. Track usage spikes that might be caused by a Distributed Denial of Service (DDoS) attack.
4. Help identify whether errors are caused by user mistakes or possible security issues (such as broken authentication).

From a performance perspective, RUM is useful to:

- See if specific regions are experiencing slower service.
- Understand the impact of software updates on the user experience.
- Spot technical failures that only happen under real usage conditions.

Both synthetic transactions and real user monitoring serve different purposes but work best when used together:
| Feature / Aspect | Synthetic Transaction | RUM (Real User Monitoring) |
|------------------|-----------------------|----------------------------|
| Nature | Simulated, predictable tests | Real-world, live user data |
| Data source | Scripted interactions (simulated users) | Actual user sessions and events |
| Availability | Runs even when no users are online | Only runs when real users are active |
| Primary value | Early warning, uptime and security baselining | True user experience, performance and behaviour insights |
| Approach | Process-based, repeatable | Behaviour-based, uncontrolled/real-world |
| Environment | Controlled environment | Uncontrolled, real-world behaviour |

For example, a company could set up synthetic tests to alert the security team at night if the login service stops working — even if no user is active — while RUM could spot that a large number of users are having trouble logging in during business hours, perhaps because of an attack or bug.

### Open Questions ###

1. What is a synthetic transaction in cybersecurity testing?

<details> <summary>Show answer</summary> A synthetic transaction is a fake or automated action designed to simulate what a real user would do, like logging in or clicking a button, to check if a system is working properly — even when no real users are using it. </details>

2. Why do organizations use synthetic transactions?

<details> <summary>Show answer</summary> Organizations use synthetic transactions to detect problems or security issues early, before real users notice, and to continuously test systems for availability, performance, and abnormal behavior. </details>

3. Give an example of how synthetic transactions might be used for an online banking website.

<details> <summary>Show answer</summary> A synthetic transaction could automatically log in with a test account every five minutes. If the login fails or is too slow, the system alerts the technical team, even if no real customer has complained yet. </details>

4. Besides performance, what kind of issues can synthetic transactions help detect?

<details> <summary>Show answer</summary> Synthetic transactions can help detect security problems like website defacement, broken login processes caused by attacks, database issues, and services pretending to be healthy when the backend is actually broken or compromised. </details>

5. What is the benefit of running synthetic transactions 24/7?

<details> <summary>Show answer</summary> Running synthetic transactions continuously helps reduce the time it takes to detect problems (Mean Time To Detect — MTTD) and ensures systems are monitored even outside business hours. </details>

6. What is baseline monitoring, and how do synthetic transactions help with it?

<details> <summary>Show answer</summary> Baseline monitoring means understanding what "normal" system behavior looks like. Synthetic transactions help establish this baseline, so it's easier to spot unusual or potentially harmful activity later on. </details>

7. What does Real User Monitoring (RUM) do differently from synthetic transactions?

<details> <summary>Show answer</summary> RUM tracks the behavior and experience of actual users in real-time, recording things like page load speed, errors, and geographic location, rather than running automated test actions. </details>

8. How can RUM help detect potential security threats?

<details> <summary>Show answer</summary> RUM can spot unusual patterns, like one user sending thousands of requests, detect bot activity, monitor DDoS attacks, and help identify whether errors are caused by users or possible security breaches. </details>

9. Why is it useful to combine synthetic transactions with Real User Monitoring?

<details> <summary>Show answer</summary> Using both provides the best coverage: synthetic transactions catch issues even when no users are online, while RUM reveals how real users experience the system during actual use — making it easier to detect both performance and security problems. </details>

10. How do synthetic transactions and RUM complement each other in detecting login issues?

<details> <summary>Show answer</summary> Synthetic transactions can detect if the login system breaks at night when no users are active, while RUM can highlight login troubles during the day when many real users encounter the same issue, helping security teams catch both types of problems. </details>

---

## 6.2.5 Code review and testing ##

In cybersecurity, code review and testing are critical to catching vulnerabilities before attackers do. Whether you’re part of a secure development lifecycle (SDLC), auditing third-party code, or helping developers fix security issues, knowing how code gets reviewed and tested can help you spot weak points and suggest better defenses.

**Code review** is the process of manually or automatically checking source code for errors, weaknesses, or security vulnerabilities before the software is released. A code review is usually done by a peer or a team of experts and focuses on quality, readability, logic, and — of course — security

For cybersecurity professionals, code reviews are a chance to detect common security flaws like:
- Hardcoded credentials.
- SQL injection risks.
- Poor input validation.
- Insecure API usage.
- Misuse of crypto libraries.

**Manual code reviews** can spot logic flaws and misuse of security features that automated tools might miss. **Automated reviews** (using static analysis tools) are great for finding repetitive coding mistakes and enforcing secure coding standards.

A Fagan inspection is a structured, formal type of code review introduced by Michael Fagan in the 1970s. Unlike casual peer reviews, Fagan inspections follow a strict process with clear roles, steps, and documentation.
The inspection usually goes like this:

| Step              | Description                                        |
|-------------------|----------------------------------------------------|
| Planning          | The inspection team is selected, and the code is prepared. |
| Overview          | The author explains the design and logic to the reviewers. |
| Preparation       | Reviewers study the code individually.             |
| Inspection Meeting| Reviewers meet to discuss and document defects.    |
| Rework            | The author fixes the problems.                     |
| Follow-up         | Reviewers verify the fixes.                        |

:bulb: In security, Fagan Inspection is especially useful for catching design-level problems and enforcing accountability, since every step is documented and roles (author, moderator, reviewer) are clearly separated.

**Static testing** means reviewing code, configuration, or architecture without executing the program. This includes both human code reviews and automated static analysis tools.
Static testing is valuable because it can detect bugs and vulnerabilities early, even before the software runs. Common findings include buffer overflows, hardcoded secrets, weak cryptographic practices, and insecure input handling.
For cybersecurity, static testing is often the first line of defense — allowing secure-by-design principles to be enforced from the start.

**Dynamic testing**, unlike static testing, runs the application and observes how it behaves in real time. Dynamic testing looks for security vulnerabilities like:
- SQL Injection.
- Cross-site scripting (XSS).
- Authentication bypass.
- Memory corruption

Dynamic testing tools (DAST — Dynamic Application Security Testing) don’t need access to the source code. Instead, they interact with the running application, much like an attacker would, which makes them ideal for identifying vulnerabilities in the final deployed environment.
Dynamic testing can be automated (via tools like Burp Suite) or manual, where testers craft custom attack payloads based on the app’s responses.

In **black box testing**, the tester has no knowledge of the application’s internals. The goal is to assess the system from an outsider’s perspective — just like a real attacker would.
In security, black box testing is commonly used for: Penetration testing,  Vulnerability scanning,  system integration testing.

:bulb: Since the tester doesn't rely on code access, black box testing is great for finding issues in real-world scenarios, such as broken access control, insecure server configurations, and input validation flaws.

**White box testing** (sometimes called clear box or transparent testing) is the opposite of black box testing. Here the tester has full knowledge of the source code, architecture, and internal logic.
This allows for deep coverage of edge cases, like:
- Identification of hidden vulnerabilities (logic errors, unsafe code paths).
- Security testing of cryptographic implementations.
- Verification of input validation, error handling, and boundary conditions.
- White box testing is often combined with static analysis to ensure that both code and design are secure.

:necktie: The most secure systems use a combination of all these practices — with static and white box techniques catching issues during development, and dynamic and black box methods simulating real-world attacks before and after release.

### Open Questions ###

1. What is the main purpose of a code review in software development?  
<details>
  <summary>Show answer</summary>
The main purpose of a code review is to find mistakes, improve code quality, and catch potential security vulnerabilities before the software is released. It also helps enforce coding standards and share knowledge within the team.
</details>

2. How does a Fagan inspection differ from a casual code review?  
<details>
  <summary>Show answer</summary>
A Fagan inspection is a formal and structured process that involves planning, preparation, and follow-ups, unlike casual code reviews which are often more informal and flexible. Fagan inspections focus on defect prevention and documentation.
</details>

3. Why is static testing important for cybersecurity?  
<details>
  <summary>Show answer</summary>
Static testing helps identify security issues like hardcoded credentials, unsafe input handling, or insecure coding practices early in development. This allows teams to fix vulnerabilities before the software runs in production.
</details>

4. When in the development cycle is static testing usually performed?  
<details>
  <summary>Show answer</summary>
Static testing is usually performed during the coding and design phase, before the software is executed. This makes it cost-effective for catching problems early.
</details>

5. What is dynamic testing, and how does it help in finding vulnerabilities?  
<details>
  <summary>Show answer</summary>
Dynamic testing involves running the application and observing its behavior under real conditions. It helps detect runtime vulnerabilities like SQL injection, XSS, or logic flaws that static testing might miss.
</details>

6. What is the main difference between black box testing and white box testing?  
<details>
  <summary>Show answer</summary>
Black box testing tests an application from an external perspective, without knowing its internal code or logic. White box testing, on the other hand, uses full knowledge of the system's internal structure to guide testing.
</details>

7. Why is black box testing useful for security assessments?  
<details>
  <summary>Show answer</summary>
Black box testing is useful for simulating real-world attacker behavior, as it reveals how the application handles unexpected input and interaction. It’s commonly used in penetration testing.
</details>

8. How does white box testing help identify deeper vulnerabilities?  
<details>
  <summary>Show answer</summary>
White box testing allows testers to explore hidden code paths, internal logic, and security controls that wouldn’t be visible from the outside. This makes it ideal for finding deep logic errors and unsafe code.
</details>

9. Why is combining static and dynamic testing considered a best practice in security?  
<details>
  <summary>Show answer</summary>
Combining static and dynamic testing gives better security coverage, since static testing can catch coding flaws early and dynamic testing can reveal runtime issues under real-world conditions. Both approaches complement each other.
</details>

10. How can Fagan inspections help improve security and code quality?  
<details>
  <summary>Show answer</summary>
Fagan inspections improve security by forcing developers and reviewers to methodically analyze code, reducing the chance of missing logic errors or insecure patterns. The structured process also creates clear accountability and documentation.
</details>


## 6.2.6 Misuse case testing ##

A **use case** describes how a system is supposed to behave when everything is working as intended. In software design, a use case defines a specific interaction between a user (or another system) and the software.For example, for an online banking application, a use case might be:“A customer logs in, views their balance, and transfers money to another account.”

**Use case testing** is the process of turning these expected behaviors into test scenarios, and verifying whether the system responds correctly. This helps confirm that:
- Legitimate users can complete their tasks.
- The system produces the expected output.
- Security mechanisms like input validation or authentication don’t break normal operations.

:necktie: From a cybersecurity perspective, use case testing helps ensure security features don’t harm usability, and that security measures don’t block legitimate actions. This is important for real-world applications, where overprotective security can sometimes cause downtime or user frustration.

While use cases focus on “how things should work”, **misuse cases** focus on “how things could go wrong.” A misuse case is a scenario where an attacker (or malicious user) tries to abuse the system in unexpected or harmful ways. For example: “An attacker tries to bypass the login by using SQL injection in the username field.”

Misuse case testing is a mindset shift: you ask “what could an attacker do here?” rather than “what should a customer do?” You design test scenarios where the goal is not to confirm expected behavior, but to see if the system:
- Rejects invalid inputs.
- Detects or blocks malicious activities.
- Handles abuse gracefully (no crashes or data leaks).

For security professionals, misuse case testing is an important technique to think like an attacker. It can reveal gaps in validation, error handling, and authorization that normal functional testing wouldn’t catch.

**UML (Unified Modeling Language)** is a standardized way to visualize a system’s design and behavior using diagrams. UML is often used by developers and architects, but security experts can also benefit from it, especially when preparing threat models or designing security controls.

Some of the most useful UML diagrams for security work are:
- Use Case Diagrams — to map user interactions with the system.
- Misuse Case Diagrams — a simple extension of use case diagrams, where attackers (or “malicious actors”) are shown trying to subvert the system.
- Sequence Diagrams — to show the order of operations or messages exchanged between system components. This can highlight attack surfaces.
- Class Diagrams — to represent the structure of the system, including relationships between modules, classes, and components.

:necktie: Security isn’t just about scanning and patching — it’s about designing systems that are secure by default and by design. Use case testing ensures the system works as intended. Misuse case testing ensures the system handles attacks safely. UML helps you communicate both.

### Open Questions ###

1. What is the main goal of use case testing in cybersecurity?  
<details>
  <summary>Show answer</summary>
The main goal of use case testing is to make sure that a system works properly for legitimate users by verifying expected behaviors, such as successful logins, transactions, or data retrieval.
</details>

2. How does misuse case testing help security experts strengthen a system?  
<details>
  <summary>Show answer</summary>
Misuse case testing helps security experts identify how attackers could abuse the system by simulating malicious behaviors, such as inputting harmful data or trying to bypass security controls.
</details>

3. What is the difference between use case testing and misuse case testing?  
<details>
  <summary>Show answer</summary>
Use case testing checks if the system handles normal, expected user actions correctly, while misuse case testing focuses on how the system reacts to malicious or unexpected actions from attackers.
</details>

4. How can UML diagrams support security analysis in software development?  
<details>
  <summary>Show answer</summary>
UML diagrams help security teams visualize how a system is designed, including the flow of data, user interactions, and connections between components — making it easier to identify potential weak spots or attack paths.
</details>

5. Why is it helpful to perform both use case and misuse case testing during software testing?  
<details>
  <summary>Show answer</summary>
Performing both use case and misuse case testing ensures that a system not only works as intended for real users but is also prepared to defend against invalid, harmful, or unexpected actions from attackers.
</details>

---

## 6.2.7 Coverage Analysis ##

Testing isn’t just about “running some checks” ,  it’s about knowing how much of your code and logic has actually been tested. Test coverage tells you which parts of your code have been exercised by your test cases and which haven’t. The higher the coverage, the lower the chance that an untested part of your system could hide a security vulnerability.

Test coverage is especially important in security-focused development because attackers often exploit the “forgotten” or poorly tested paths in software logic. If a branch, condition, or function hasn’t been tested, no one can guarantee it will behave securely in production.

At its core, test coverage is calculated as:

**Test Coverage (%) = (Number of items tested / Total number of items) × 100**

The “items” depend on what you’re measuring. For example:
- If you're counting statements: the number of lines of code tested vs. total lines.
- If you're counting branches: the number of decision paths tested vs. total decision paths.
- If you're counting functions: the number of functions called vs. total functions in the program.

Types of Test Coverage are:

| Coverage Type     | Description                                                                                              | Example                                                                                           | Security Relevance                                                                                  |
|-------------------|----------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|
| **Statement Coverage** | Measures whether each line of code (statement) has been executed at least once during testing.           | If a program has 100 lines of code and your tests execute 90, your statement coverage is 90%.      | Ensures no part of the code goes completely untested, where hidden bugs and security flaws may exist. |
| **Branch Coverage**    | Focuses on decision points, like if-else, switch cases, and loops. Ensures every branch is tested.       | An if statement has two paths (true and false) — both must be tested for 100% branch coverage.     | Critical for security, as untested paths may behave incorrectly or leak sensitive data.               |
| **Condition Coverage** | Tests each individual condition inside compound decisions.                                             | For `if (A && B)`, both A and B must be tested as true and false in various combinations.          | Helps catch cases where individual conditions fail even if the overall decision looks tested.         |
| **Function Coverage**  | Measures whether each function or method in the code has been called at least once.                    | Verifies that all pieces of the application are exercised, not just common or high-traffic paths.  | Unused/rarely used functions can hide risks like legacy code issues, backdoors, or logic errors.      |
| **Loop Coverage**      | Verifies loops are tested under all reasonable conditions: zero, one, and multiple iterations.          | Ensures loop behavior is validated under different iteration counts.                              | Prevents errors and security issues such as buffer overflows or infinite loops under attack.           |

### Open Questions ###

1. What is the main purpose of test coverage analysis in software security testing?  
<details>
  <summary>Show answer</summary>
The main purpose of test coverage analysis is to measure how much of a system’s code has been exercised by tests, helping ensure that untested parts don’t hide security vulnerabilities or logic errors.
</details>

2. What does the test coverage formula measure, and how is it calculated?  
<details>
  <summary>Show answer</summary>
The test coverage formula measures the percentage of tested items (like statements, branches, or functions) compared to the total available items, using:  
<br>
Test Coverage (%) = (Number of items tested / Total number of items) × 100.
</details>

3. Why is branch coverage especially important for detecting security issues?  
<details>
  <summary>Show answer</summary>
Branch coverage is important because it ensures both outcomes of decision points (if-else, switch, etc.) are tested, reducing the risk that attackers could exploit logic paths that were never tested.
</details>

4. How does loop coverage help improve the security of an application?  
<details>
  <summary>Show answer</summary>
Loop coverage improves security by making sure loops handle all expected scenarios — including zero iterations, one iteration, and many iterations — which helps prevent issues like infinite loops, buffer overflows, or logic bypasses.
</details>

5. Why isn’t 100% statement coverage alone enough to guarantee secure software?  
<details>
  <summary>Show answer</summary>
100% statement coverage only proves that each line of code ran at least once, but it doesn’t guarantee all possible decision paths, conditions, or edge cases were tested, leaving room for hidden security flaws.
</details>

---

## 6.2.8 Interface testing (e.g., user interface, network interface, application programming interface (API)) ##

When people and systems need to communicate, they use something called an **interface**. An interface is the part of the system where two things meet and exchange information. You use interfaces every day, even if you don’t notice. For example, when you click a button on a website, that button is part of a user interface. When two computers send data over the internet, the network card and cable are part of a network interface. 

In cybersecurity, interfaces are important because they are often the first place attackers try to break in. If an interface doesn’t check the data it receives properly, or if it gives away too much information, it can become a security risk. That’s why testing interfaces is one of the basic jobs for anyone securing a system.

One type of interface is the **Graphical User Interface**, or GUI. This is the part of a program that users can see and click on, like buttons, forms, checkboxes, and menus. In security testing, checking the GUI means making sure it doesn’t allow anyone to type in harmful input, like special characters that could attack the database, and that it doesn’t show sensitive information by mistake.

Another type is the **Command Line Interface**, or **CLI**. This is where users type text commands instead of clicking on things. You’ll often see this used on servers or technical systems. In this case, testing means checking if the commands require the right permissions, if error messages are too helpful to an attacker, and if the system blocks invalid or dangerous commands.

A third important type is **API interfaces**. APIs let two programs talk to each other, often over the internet, without a human involved. For example, a mobile banking app uses an API to ask the bank’s server for your balance. There are different kinds of APIs, like REST APIs (common on websites), RPC (Remote Procedure Calls), and IPC (Inter-Process Communication). Testing APIs is very important in security, because if the API accepts the wrong data or has weak security checks, attackers could steal data or control the system.

:bulb: **REST APIs** are the most common type you’ll find on the web. “REST” stands for Representational State Transfer. These APIs usually work over HTTP or HTTPS — the same way websites do — and use URLs to send requests and responses, often in formats like JSON or XML. For example, when a mobile app checks your bank balance, it is usually sending a REST API request to the bank’s server. Security issues happen when the server does not properly check the data it receives, or if the system sends back more information than it should (this is called “data leakage”). If an attacker finds out that the API accepts unexpected inputs, they can often send crafted requests to read, change, or even delete data they shouldn’t be able to access.

**RPC**, or Remote Procedure Call, is another type of API. Instead of using URLs and resources like REST, RPC works by calling functions or procedures directly on a remote system — as if the function were local, even though it’s on another computer. This is faster and more direct but can be riskier. If an attacker can trigger a function remotely, especially one that changes data or performs admin-level tasks, they could cause a lot of damage. Testing RPC interfaces means making sure only authorized users can call these functions, and that the data being sent is validated before the remote server acts on it.

**IPC**, or Inter-Process Communication, is used when two software processes need to talk to each other on the same system or within a local environment. This is not usually across the internet but still very important, especially in operating systems or between security tools. IPC can use methods like shared memory, message queues, or sockets. If an attacker can hijack IPC communication or inject fake data, they might control a trusted process or crash a critical part of the system.


**Web interfaces** are another area of focus. When you visit a website and log in, or click on links, you’re using a web interface. Hackers often try to attack web interfaces by sending special input that the system doesn’t expect, which can cause it to behave badly. Testing here involves checking if the site handles wrong or malicious data safely, and whether security features like encryption are working.

**Network interfaces** are the parts of a device that connect to other computers. For example, your Wi-Fi adapter or network cable port. Testing network interfaces often involves scanning for open ports, checking which services are running, and making sure only the correct traffic is allowed in and out.

Last but not least are **physical interfaces**. These are real-world connections like USB ports or cables. A hacker could try to plug a malicious USB into a server or computer. Testing these interfaces helps check that the system can handle bad hardware connections safely, or that only trusted people can access those ports.

Testing interfaces is about more than just making sure the system “works” — it’s about making sure the system stays safe even when someone is trying to break it. Many attacks begin by finding weaknesses in the way systems communicate, so careful testing of all interfaces helps catch problems before attackers do.

:necktie: When testing interfaces, you should always ask:
Can the system handle wrong or strange data without crashing or misbehaving?
Does the system give away information that it shouldn’t?
Are all communications secure and properly checked?
If the answer is “no” to any of these questions, the interface could be a security risk.

### Open Questions ###

1. What is an interface in the context of computing and cybersecurity?  
<details>
  <summary>Show answer</summary>
An interface is the part of a system where two things — like a person and a program, or two computers — meet and exchange information. Interfaces are everywhere, from buttons on websites to network ports.
</details>

2. Why are interfaces important to test in cybersecurity?  
<details>
  <summary>Show answer</summary>
Interfaces are important to test because they are often the first place attackers try to break in. If an interface accepts bad data or gives too much information away, hackers can use that to attack the system.
</details>

3. What is a Graphical User Interface (GUI) and how can it become a security risk?  
<details>
  <summary>Show answer</summary>
A Graphical User Interface (GUI) is the part of a program that users see and interact with, like buttons and forms. If the GUI doesn’t handle input safely, a hacker could type harmful data and trick the system.
</details>

4. What is a Command Line Interface (CLI) and why should it be tested?  
<details>
  <summary>Show answer</summary>
A Command Line Interface (CLI) is where users type commands instead of clicking with a mouse. Testing ensures only authorized users can use commands and that dangerous or invalid commands are properly blocked.
</details>

5. What do APIs do and why is testing them important for security?  
<details>
  <summary>Show answer</summary>
APIs allow programs to communicate and share data. If APIs are not tested carefully, attackers might send fake or harmful requests and gain unauthorized access to data or system functions.
</details>

6. What is a REST API and how could an attacker abuse it?  
<details>
  <summary>Show answer</summary>
REST APIs send requests over the web using URLs and formats like JSON. If an attacker sends unexpected or fake data, they might get private information or change data they are not allowed to.
</details>

7. How is RPC (Remote Procedure Call) different from REST, and what risks does it bring?  
<details>
  <summary>Show answer</summary>
RPC lets one program call a function on another computer directly. If this isn’t secured, an attacker might trigger dangerous functions remotely and take control or damage the system.
</details>

8. What is Inter-Process Communication (IPC) and why could it be dangerous?  
<details>
  <summary>Show answer</summary>
IPC allows two processes on the same system to talk to each other. If a hacker hijacks this communication, they could trick the system into doing something it shouldn’t or cause it to crash.
</details>

9. Why are web interfaces a common target for attackers?  
<details>
  <summary>Show answer</summary>
Web interfaces are often attacked because users enter data directly. If the system doesn’t check this data correctly, attackers can send malicious inputs and take advantage of the website.
</details>

10. What are physical interfaces, and how can they be tested for security?  
<details>
  <summary>Show answer</summary>
Physical interfaces, like USB ports, can allow attackers to plug in harmful devices. Security testing helps check if the system can block untrusted hardware or alert users to suspicious physical connections.
</details>

## 6.2.9 Breach attack simulations ##

Breach and Attack Simulation (BAS) is a security testing approach where automated tools continuously simulate real-world cyberattacks against your systems to test whether your defenses are working properly. Unlike traditional vulnerability scanning, which focuses on finding weaknesses in software or configurations, BAS tools behave more like real attackers — running attack scenarios that mimic malware infections, privilege escalation, lateral movement, data exfiltration, and more.

The purpose of BAS is to give security teams constant, realistic feedback on how effective their security controls are. It’s no longer enough to rely on annual penetration tests or basic vulnerability scans — attackers are working 24/7, so defenses must be tested just as often. BAS platforms make this possible by running tests in a controlled and repeatable way, without harming the production environment.

When a BAS tool runs, it uses scripts or agents to simulate different parts of an attack chain — for example, trying to send malicious payloads through email, testing firewall rules, exploiting lateral movement paths in the internal network, or checking if endpoint protection can stop known ransomware samples. These simulations allow companies to see where gaps exist in their prevention, detection, and response processes — and fix them before real attackers arrive.

:link: There are several popular BAS products on the market today. Some well-known names include:
- AttackIQ: [https://www.attackiq.com/](https://www.attackiq.com/)
- SafeBreach: [https://www.safebreach.com/](https://www.safebreach.com/)
- XM Cyber: [https://xmcyber.com/](https://xmcyber.com/)
- Picus Security: [https://www.picussecurity.com/](https://www.picussecurity.com/)
- Cymulate: [https://cymulate.com/](https://cymulate.com/)

You can roughly group BAS simulations by the target (what the attacker is trying to reach) or the vector (the method used to reach it).

| Focus Area | Examples / Typical Targets |
|------------|---------------------------|
| **By Target** | - Endpoint testing (workstations, laptops, servers)  <br> - Network infrastructure (routers, switches, firewalls)  <br> - Cloud services (AWS, Azure, Google Cloud)  <br> - Active Directory / Identity systems  <br> - Web applications and APIs  <br> - Databases and storage systems |
| **By Vector** | - Email-based attacks (phishing, malicious attachments)  <br> - Web-based attacks (drive-by downloads, command injection)  <br> - Lateral movement (using stolen credentials or exploits to move inside the network)  <br> - Malware execution and evasion (testing antivirus and EDR detection)  <br> - Data exfiltration (detecting if sensitive data can leave the network unnoticed) |

:necktie: BAS helps turn security assumptions into facts. It answers important questions like: Are my detection rules working? Will my EDR actually stop this attack? Is lateral movement possible from a compromised user account? Instead of waiting for a real breach or a red team engagement once a year, BAS offers continuous validation and measurable improvement of your security posture.

### Open Questions ###

1. What is the main goal of Breach and Attack Simulation (BAS)?

<details> <summary>Show answer</summary> The main goal of BAS is to simulate real-world cyberattacks in a safe, automated way to check if your security systems can prevent, detect, and respond correctly before real attackers strike. </details>

2. How is BAS different from traditional vulnerability scanning?

<details> <summary>Show answer</summary> Unlike vulnerability scanning, which looks for known weaknesses in software or configurations, BAS actively simulates attacker behavior — testing the full attack path including malware, lateral movement, and data theft. </details>

3. Why is it important to run BAS tools continuously instead of only once or twice a year?

<details> <summary>Show answer</summary> Attackers can target systems at any time, not just once a year, so continuous BAS testing ensures security teams catch weaknesses early, measure their defenses, and close gaps before a real incident happens. </details>

4. What kinds of attack scenarios can BAS tools simulate?

<details> <summary>Show answer</summary> BAS tools can simulate many attack scenarios such as phishing emails, malware infections, privilege escalation, firewall evasion, lateral movement, and even data exfiltration, helping expose weaknesses across systems. </details>

5. How can BAS simulations be categorized to better understand security testing?

<details> <summary>Show answer</summary> BAS simulations can be categorized by their target (like endpoints, cloud services, or web apps) or by the attack vector used (like phishing, malware, or lateral movement), which helps structure security testing efforts. </details>

---

## 6.2.10 Compliance Checks ##

Compliance checks are an essential part of any organization’s security strategy. Their goal is simple: to make sure that the systems, processes, and data handling practices inside a company meet the rules set by governments, regulators, and industry bodies. These rules are often there to protect customers, ensure privacy, and make sure sensitive data is handled responsibly.

:necktie: Compliance isn’t just about avoiding fines — it’s about proving that your security efforts match an accepted standard, which builds trust with customers and partners. 

:necktie: One of the first things to understand about compliance is that it heavily depends on where your organization operates. Different countries (and sometimes different regions within a country) have different laws about how data must be handled.

This means cybersecurity teams can’t apply a single checklist everywhere. The laws that apply in Germany are not the same as those in California or Singapore. Part of running compliance checks is knowing the geography of your data and systems — and matching that to the correct set of rules.

Compliance is also highly industry-dependent. Each sector has its own specific concerns and risks, so different rules apply. Here are a few common examples:
- Finance: Financial companies often deal with credit card details, personal IDs, and banking information, which makes standards like PCI-DSS (Payment Card Industry Data Security Standard) extremely important. In banking, regulations like SOX (Sarbanes-Oxley Act) and GLBA (Gramm-Leach-Bliley Act) apply.
- Healthcare: Hospitals and clinics handle deeply sensitive medical records, which are covered by HIPAA in the U.S. and GDPR in Europe.
- Retail: Any company that processes payments must comply with PCI-DSS, while e-commerce platforms must consider local consumer protection and privacy laws.
- Public Sector: Governments often require compliance with national cybersecurity frameworks, like NIST 800-53 or ISO 27001.

Because every industry has its own data types and risks, compliance checks must always reflect the context of the business, not just general security best practices.

Running a compliance check isn’t only about reviewing documents. It’s a mix of technical audits, process reviews, and human verification. Here’s how security teams usually approach it:

| Step                          | Description |
|-------------------------------|-------------|
| **Understand the Requirements** | First, the team must clearly know which regulation applies to the company. Sometimes this involves multiple overlapping rules (for example, both GDPR and PCI-DSS if you store European user data and process payments). Each regulation will have specific controls and security expectations. |
| **Map Requirements to Systems** | Next, you map the legal or industry requirements to the specific parts of your IT environment. For example: <br>• If GDPR says you must secure personal data, you check which databases hold that data. <br>• If PCI-DSS demands encryption, you verify the encryption setup for payment systems. |
| **Collect Evidence** | Compliance checks require proof. It’s not enough to say “we encrypt our data” — you must provide logs, screenshots, audit trails, or automated test results that show the encryption is active and working. |
| **Automated Scanning and Manual Audits** | Many companies use automated tools to continuously monitor for compliance violations (for example, misconfigured cloud storage or unpatched systems). These tools help flag common errors. However, a human still needs to review policies, procedures, and some security controls manually, especially around incident response and access management. |
| **Gap Analysis and Reporting** | After the check, the team prepares a gap report that shows where the company is compliant and where fixes are needed. This report is usually shared with management or compliance officers, who assign priorities and resources for fixing the gaps. |
| **Documentation and Certification** | In many cases, once a company meets compliance, the proof is formalized as a certificate or attestation. Auditors, security teams, and sometimes external consultants are involved in this step. |

### Open Questions ###

1. What is the main goal of a compliance check in cybersecurity?  
<details>
  <summary>Show answer</summary>
The goal is to verify that your systems, processes, and data handling meet specific security and privacy rules set by governments, industry standards, or contracts. It helps ensure you’re following the law and protecting sensitive information.
</details>

2. Why are compliance requirements different depending on your location?  
<details>
  <summary>Show answer</summary>
Laws and regulations are created by governments, and each country or region has its own legal requirements. For example, GDPR applies in Europe, while U.S. companies might need to meet HIPAA or SOX depending on their business.
</details>

3. How does your industry affect which compliance rules you must follow?  
<details>
  <summary>Show answer</summary>
Different industries face different risks, so the rules are tailored to the business. Financial institutions follow standards like PCI-DSS or SOX, while healthcare providers must meet HIPAA and data protection laws for patient information.
</details>

4. What’s the difference between a vulnerability scan and a compliance check?  
<details>
  <summary>Show answer</summary>
A vulnerability scan focuses on finding technical weaknesses in systems, like unpatched software or open ports. A compliance check verifies whether your entire environment, including policies and procedures, meets the required rules.
</details>

5. What are the first two steps in running a compliance check?  
<details>
  <summary>Show answer</summary>
First, you identify which regulations apply to your business. Second, you map those regulations to your technical systems, policies, and teams so you can properly check if you meet the requirements.
</details>

6. Why is collecting evidence important in a compliance check?  
<details>
  <summary>Show answer</summary>
Compliance requires proof that security controls are in place and working. Evidence can include system logs, policy documents, audit reports, or screenshots to demonstrate compliance to regulators or auditors.
</details>

7. Can compliance checks be fully automated?  
<details>
  <summary>Show answer</summary>
Some parts of compliance checks can be automated, like scanning systems for misconfigurations or missing patches, but a human is still needed to review policies, assess risks, and check if procedures are being followed.
</details>

8. What happens after a compliance check finds a problem?  
<details>
  <summary>Show answer</summary>
If a compliance check finds a problem, the issue is recorded and reported as a "gap" that must be fixed. Once all gaps are addressed, the company can pass an audit and show regulators or customers that it meets the required standards.
</details>



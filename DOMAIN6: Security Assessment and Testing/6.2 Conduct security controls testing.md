## 6.2.1 Vulnerability Assessment ##

In cybersecurity, vulnerabilities must be clearly described so that both humans and automated systems can communicate about them. Several naming standards and scoring systems exist to help standardize vulnerability data across the industry.

**SCAP (Security Content Automation Protocol)** is a framework developed by NIST (National Institute of Standards and Technology) to automate the process of checking systems for vulnerabilities and configuration issues. SCAP combines multiple standards under one umbrella so tools can speak the same language.

:link: [Security Content Automation Protocol SCAP.](https://csrc.nist.gov/projects/security-content-automation-protocol)

**CVE (Common Vulnerabilities and Exposures)** assigns a unique ID to every known vulnerability. For example: CVE-2023-12345.
This makes it easy to reference the same issue across vendors, tools, and reports. CVE entries contain a short description, a publication date, and links to advisories and patches.

:link: [https://cve.mitre.org/](https://www.cve.org/)

These standards help automate vulnerability discovery, analysis, and reporting, making security assessments faster, more reliable, and easier to maintain:

| Standard | Purpose | Key Features | Example / Use Case |
|----------|----------|--------------|---------------------|
| **CVSS** (Common Vulnerability Scoring System) | Assigns a severity score (0.0–10.0) to vulnerabilities | Considers exploitability, confidentiality, integrity, availability, and environmental factors | A vulnerability with CVSS 9.8 is prioritized for immediate patching |
| **CCE** (Common Configuration Enumeration) | Identifies insecure system configurations | Provides unique IDs for misconfigurations instead of software bugs | Example: Windows Server allows weak password hashes |
| **CPE** (Common Platform Enumeration) | Standardized naming for software, hardware, and OS | Ensures scanners match the correct software version to vulnerabilities | “cpe:2.3:a:microsoft:office:2019” used in a vulnerability database |
| **XCCDF** (eXtensible Configuration Checklist Description Format) | Defines structured security checklists and rules | Provides pass/fail criteria for compliance assessments | An XCCDF file specifies Linux hardening rules (e.g., disable root SSH login) |
| **OVAL** (Open Vulnerability and Assessment Language) | Machine-readable vulnerability definitions | Scanners use OVAL tests to check system compliance automatically | Detecting if a patch is missing by running OVAL-defined checks |

A **vulnerability scan** inspects systems for known security weaknesses. These scans compare system data against vulnerability databases and known exploit conditions. Tools like Nessus, OpenVAS, Qualys, or Nexpose perform these scans and typically check for:
- Missing patches
- Default or weak configurations
- Exposed ports and services
- Known software flaws (linked to CVEs)

Vulnerability scanning can be done with or without credentials:
- Unauthenticated scan: limited to external inspection (open ports, service banners).
- Authenticated scan: allows deeper inspection of patch levels, file permissions, and configurations.

Before doing a vulnerability scan, security teams often run a **discovery scan** to find out what devices and systems exist on the network, because you can’t protect what you don’t know about. Discovery scans tell you which machines are online, what services are running, and which ports are open, which helps you make a complete inventory. When you scan a network, you also learn about the status of ports, which are like digital doors that let data in and out of a system. Ports can be open, which means the door is wide open and a service is ready to accept connections; closed, which means the door is shut but the system is reachable; filtered, which means the firewall is hiding the port so you can’t easily tell if it’s open or closed; or unfiltered, which means the port is reachable but the scanner can’t determine its exact state. Understanding these port states helps you see which systems are exposed to the internet or the internal network, and where attackers might focus their efforts. When it comes to scanning for vulnerabilities, you can focus on the whole network or specialize by type of system. For example, network vulnerability scans are used to check servers, routers, printers, and computers to see if there are weak spots like old software, unpatched services, misconfigurations, or exposed administration interfaces. 

If the focus is on websites and web applications, you would use a **web vulnerability scanner**, which looks for problems like SQL injection, where an attacker can trick the website into running malicious database commands, or cross-site scripting, where attackers inject code into pages that other users see. Web scanners also check if sensitive data is protected with encryption, if session tokens are secure, and if security headers are missing. 

**Databases** also have their own types of security scans, because they often store sensitive business or customer information. A database scan looks for things like weak passwords, insecure settings, missing updates, or excessive user permissions that allow people to access more data than they should. 

After scanning is done and all potential problems are found, the real work begins — which is managing the vulnerabilities. This is called the vulnerability management process, and it helps you handle problems in a way that is organized and reduces risk. First, you must keep a complete and up-to-date list of all devices, servers, and systems in your organization, because if you miss something, you won’t be scanning it or fixing it, and attackers might find it first. Then, when vulnerabilities are identified by your scanner, each finding must be carefully reviewed to make sure it’s a real issue and not a false alarm. Some vulnerabilities look dangerous but are not exploitable on your system due to specific configurations or other defenses. After confirming the real risks, the next step is to prioritize them, because not all problems are equally urgent. Security teams usually rely on the CVSS score, the importance of the affected system, and whether the vulnerability is known to be exploited in real-world attacks. Critical vulnerabilities on systems exposed to the internet are usually fixed first, especially if the system stores customer data or controls important business functions. Once you know which vulnerabilities need fixing, the next step is remediation, which means applying patches, changing settings, disabling risky services, or putting extra protections in place. If the vulnerability can’t be fixed immediately, you might reduce the risk temporarily by blocking network access or isolating the affected system. After the fix is applied, you should always check to make sure the problem is really solved, either by running another scan or testing manually. Finally, everything should be recorded in reports, so the organization can keep track of which systems were affected, how long it took to fix them, and what the overall risk level is. These reports also help show auditors and regulators that the company takes security seriously. Over time, security teams look for patterns and try to improve their processes, so fewer vulnerabilities slip through the cracks in the future. This whole cycle — from discovering systems, scanning for problems, fixing them, verifying the fixes, and reporting results — repeats continuously, because new vulnerabilities are discovered all the time, and old systems can fall out of compliance as software ages or new configurations are deployed. Security assessments are a core part of making sure your systems are protected against both known and unknown threats, and when done regularly and carefully, they greatly reduce the risk of data breaches, downtime, and costly cyberattacks.

| Step | Description | Key Points |
|------|-------------|------------|
| **1. Asset Inventory** | Maintain an up-to-date list of devices, servers, and systems. | Missing assets = unscanned, unprotected, exploitable by attackers. |
| **2. Vulnerability Identification** | Use scanners to find potential problems. | Review carefully to confirm real issues and filter false positives. |
| **3. Risk Validation** | Assess whether vulnerabilities are truly exploitable in your environment. | Some may look severe but aren’t exploitable due to configs/defenses. |
| **4. Prioritization** | Rank vulnerabilities by urgency. | Consider CVSS score, criticality of the system, and known exploits. |
| **5. Remediation** | Fix vulnerabilities by patching, changing configs, disabling risky services, or adding protections. | If not possible immediately, apply temporary risk reduction (e.g., block network access). |
| **6. Verification** | Confirm that fixes worked. | Re-scan or manually test to ensure vulnerabilities are resolved. |
| **7. Reporting** | Document vulnerabilities, fixes, timelines, and risk levels. | Reports show accountability and compliance for auditors/regulators. |
| **8. Continuous Improvement** | Analyze trends and refine processes. | Goal: reduce recurring issues, improve speed/effectiveness. |
| **Ongoing Cycle** | Repeat scanning and fixing continuously. | New vulnerabilities appear constantly; old systems can drift out of compliance. |

### Open Questions ###

1. Why do we need naming standards like CVE when dealing with cybersecurity vulnerabilities?

<details> <summary>Show answer</summary> Naming standards like CVE allow everyone — vendors, researchers, security tools — to talk about the same vulnerability using a common label. This avoids confusion and ensures consistency across reports, patches, and alerts. </details>

2. What is the purpose of the CVSS score when evaluating vulnerabilities?

<details> <summary>Show answer</summary> The CVSS score helps security teams understand how severe a vulnerability is, and decide how urgently it needs to be fixed. High scores mean the vulnerability is easier to exploit or causes more damage. </details>

3. How does CPE help scanners during a vulnerability assessment?

<details> <summary>Show answer</summary> CPE makes sure that scanners match the correct vulnerability to the exact software, hardware, or operating system version. This reduces false alarms and ensures only relevant issues are reported. </details>

4. What makes SCAP important in security automation?

<details> <summary>Show answer</summary> SCAP helps different security tools use the same rules and formats to automatically check systems for vulnerabilities and misconfigurations, making security checks faster and more reliable. </details>

5. Why is OVAL useful when scanning for vulnerabilities?

<details> <summary>Show answer</summary> OVAL turns vulnerability descriptions into machine-readable checks, so automated tools can scan systems without human interpretation, improving speed and consistency. </details>

6. What does an XCCDF file do in a security assessment?

<details> <summary>Show answer</summary> XCCDF defines security rules in a structured format that tools can follow, helping automate the process of verifying system configurations and hardening servers against attacks. </details>

7. Why are vulnerability scans usually combined with discovery scans?

<details> <summary>Show answer</summary> Discovery scans help identify all the devices and services on a network, making sure that vulnerability scans don’t miss systems that are unknown or hidden. </details>

8. What can you learn by checking the state of a network port during a scan?

<details> <summary>Show answer</summary> By checking port states, you can learn if a service is running and reachable (open), blocked (filtered), disabled (closed), or uncertain (unfiltered). This helps detect exposure points for potential attacks. </details>

9. How does web vulnerability scanning differ from network vulnerability scanning?

<details> <summary>Show answer</summary> Web vulnerability scanning focuses on flaws in websites and apps, like SQL injection or broken encryption, while network vulnerability scanning targets devices, services, and configurations on a broader network level. </details>

10. Why is vulnerability management more than just scanning?

<details> <summary>Show answer</summary> Vulnerability management includes identifying, validating, prioritizing, fixing, and verifying vulnerabilities. This structured approach prevents attackers from exploiting known issues and helps maintain long-term security. </details>

---

## 6.2.2 Penetration testing (e.g., red, blue, and/or purple team exercises) ##

Penetration testing, often called **pentesting**, is a security testing method where ethical hackers simulate real-world attacks on systems, networks, applications, or even physical locations to find weaknesses before malicious attackers do. The goal of penetration testing is to identify vulnerabilities in a controlled and safe way, so that companies can fix them before they are exploited. Pentesters act like real attackers, but with permission from the company, and usually follow a carefully agreed plan to avoid damage or disruption.

There are different types of penetration testing, depending on how much information the tester is given before the test begins. The three most common types are white box, gray box, and black box testing. 

| Test Type | Knowledge Provided | Simulates | Strengths | Limitations | Typical Use Cases |
|-----------|--------------------|-----------|-----------|-------------|-------------------|
| **White box testing** | Full knowledge — architecture diagrams, source code, config files, sometimes admin access. | Insider attack or attacker who already has extensive internal info. | Very deep analysis; finds design flaws, insecure configs, and code-level issues; efficient at locating logic bugs. | Less realistic for external attacks; may miss issues an external attacker would exploit through discovery. | Code reviews, secure SDLC checks, deep application or system audits. |
| **Gray box testing** | Partial knowledge — some credentials or network details, but no full source/config access. | Attacker with limited insider access (e.g., employee or compromised account) trying to escalate or move laterally. | Good balance of realism and depth; can find privilege escalation and lateral-movement issues; more focused than black box. | May still miss deep code-level problems; depends on the quality of partial info provided. | Web app tests with user-level access, internal web services, employee-facing systems. |
| **Black box testing** | No internal knowledge — tester uses public info, open ports, and visible services only. | External attacker approaching from the internet or public networks. | Very realistic for external threats; tests discovery and external attack surface; useful for public-facing assets. | May miss deep internal or code-level vulnerabilities; can be time-consuming to discover complex issues. | External penetration tests for websites, mail servers, VPNs, and perimeter services. |

Before a penetration test starts, both the customer and the pentesting team agree on a clear set of **rules of engagement**. These rules are essential to avoid misunderstanding, legal issues, or accidental disruption of business operations. The rules define what systems are in scope, what testing techniques are allowed, what times the tests can take place, what to do if a critical vulnerability is found, and how the results will be reported. Common pentesting rules also include instructions for handling sensitive data and communication during and after the test.

Pentesting is usually performed in structured phases. 

The first phase is **Planning and Reconnaissance**, where the tester gathers information about the target from public sources, like domain names, DNS records, website content, employee emails, or social media. 
In some cases, this step uses both passive and active scanning. 

The second phase is **Scanning**, which involves using automated tools or manual techniques to map the network, identify open ports, services, and vulnerabilities. 

The third phase is **Gaining Access**, where the tester tries to exploit weaknesses to enter the system. Once access is obtained.

The fourth phase, **Maintaining Access**, simulates how long an attacker could stay undetected by setting up backdoors or creating fake accounts. 

The fifth phase is **Analysis and Reporting**, where the tester documents everything: which vulnerabilities were found, how they were exploited, what level of access was gained, and recommendations on how to fix the problems.

While most people think of penetration testing as something that happens on computers and networks, there is also physical **penetration testing**. In this type of test, security professionals attempt to physically breach the security of buildings, offices, or data centers. The goal is to test the effectiveness of physical controls such as locks, security guards, surveillance cameras, access badges, alarms, and visitor procedures. Physical pentesting can include techniques like lock picking, tailgating (following an authorized person into a secured area), bypassing access controls, social engineering (like pretending to be a delivery person), and even planting hardware devices like rogue Wi-Fi access points or USB drop attacks. Physical penetration testing helps organizations understand how secure their premises are against both casual and targeted intrusions, and whether their staff is following proper security protocols.

:necktie: Overall, penetration testing is a critical part of modern cybersecurity programs. Whether the focus is digital systems, web applications, wireless networks, cloud environments, or physical access, the objective is always the same: simulate an attack in a safe and controlled way to detect weak points before someone malicious does. Penetration tests should always end with a clear, structured report that explains not just the technical problems found, but also the business risk and the recommended fix for each issue. This way the organization can prioritize remediation and improve its security posture in a continuous cycle of assessment, fixing, and retesting.

The terms Red Team, Blue Team, and Purple Team describe roles and exercises designed to improve an organization’s defense against real-world attacks. Each “team” has a specific function in the security testing process, and together they create a cycle of attack, defense, and learning that helps organizations strengthen their security posture.

| Team | Role | Main Activities | Tools & Techniques | Goal | Collaboration Style |
|------|------|----------------|--------------------|------|---------------------|
| **Red Team** | Acts like an advanced attacker, simulating real-world cyberattacks against systems, networks, apps, and people. | Intelligence gathering, exploiting vulnerabilities, social engineering, phishing, bypassing physical security, planting rogue devices, pivoting between systems. | Exploit frameworks, phishing kits, malware, rogue devices, stealth techniques. | Test how well the organization can detect and respond to advanced, realistic attacks without warning. | Works covertly, usually without SOC/IT staff knowledge. |
| **Blue Team** | Defensive security team monitoring and protecting systems in real time. | Log analysis, intrusion detection, monitoring SIEM alerts, stopping attacks, containing threats, investigating incidents, hardening systems, patching, training users. | IDS/IPS, SIEM platforms, endpoint protection, threat intelligence, monitoring tools. | Reduce attack surface, detect intrusions early, respond effectively, and improve defenses over time. | Works continuously, reacts to Red Team attacks when they happen. |
| **Purple Team** | Bridge between Red and Blue Teams to improve collaboration and effectiveness. | Documenting attacks step by step, explaining techniques, showing Blue Team how attacks worked, suggesting detection & prevention improvements. | Reporting tools, knowledge-sharing platforms, simulations, collaborative exercises. | Accelerate learning, strengthen detection & prevention, ensure Red-Blue collaboration. | Works side by side with both teams, often more of an approach than a separate team. |

:necktie: Red, Blue, and Purple teaming exercises are extremely valuable because they move security from theory to practice. A company might have the best security policies on paper, but until a Red Team tests them and a Blue Team defends against them, no one knows how those defenses will hold up under real attack conditions. Red Teams show what an attacker can do, Blue Teams show how well the defenses hold up, and Purple Teams make sure everyone learns and improves after every test. Together, these teams form a continuous loop of improvement that helps organizations prepare for real cyber threats.

### Open Questions ###

1. What is the main goal of penetration testing?  
<details>  
  <summary>Show answer</summary>  
The main goal of penetration testing is to safely simulate real-world cyberattacks to find and fix vulnerabilities before malicious attackers exploit them.  
</details>  

2. Why do companies allow ethical hackers to perform penetration tests on their systems?  
<details>  
  <summary>Show answer</summary>  
Companies allow ethical hackers to perform penetration tests to uncover weaknesses in a controlled environment and strengthen their defenses.  
</details>  

3. What are the three most common types of penetration testing based on knowledge shared with the tester?  
<details>  
  <summary>Show answer</summary>  
The three most common types of penetration testing are white box, gray box, and black box testing.  
</details>  

4. In white box testing, what kind of information is typically shared with the pentester?  
<details>  
  <summary>Show answer</summary>  
In white box testing, the pentester is given full knowledge of the target system, including source code, architecture diagrams, and configuration files.  
</details>  

5. What real-world scenario does gray box testing aim to simulate?  
<details>  
  <summary>Show answer</summary>  
Gray box testing simulates the scenario where an attacker has limited insider knowledge or access, similar to a compromised employee account or partial system breach.  
</details>  

6. Why is black box testing useful for testing public-facing systems?  
<details>  
  <summary>Show answer</summary>  
Black box testing is useful for assessing the security of public-facing systems, because it mimics how an external attacker would approach the target without any prior knowledge.  
</details>  

7. What is the purpose of defining “rules of engagement” before starting a penetration test?  
<details>  
  <summary>Show answer</summary>  
Defining rules of engagement helps ensure that both the tester and the organization are clear on what is allowed, what systems are in scope, and how to handle risks or discoveries during the test.  
</details>  

8. What happens during the Planning and Reconnaissance phase of a penetration test?  
<details>  
  <summary>Show answer</summary>  
During the Planning and Reconnaissance phase, testers gather public information about the target, such as domain names, open services, and employee details.  
</details>  

9. What does the Scanning phase of a penetration test focus on?  
<details>  
  <summary>Show answer</summary>  
The Scanning phase focuses on identifying open ports, active services, and potential vulnerabilities using automated tools and manual techniques.  
</details>  

10. What is the Gaining Access phase designed to test in a penetration test?  
<details>  
  <summary>Show answer</summary>  
The Gaining Access phase tests whether the identified vulnerabilities can be exploited to enter or control the target system.  
</details>  

---

## 6.2.3 Log Reviews ##

A **log review** is the process of systematically examining log files to identify abnormal patterns, unauthorized actions, misconfigurations, or security incidents. Since logs record nearly every important event in a digital environment, they often provide the earliest indicators of compromise or technical failure.

Regular log reviews allow organizations to spot signs of trouble such as repeated failed logins, privilege escalation, system crashes, unexpected software installations, network anomalies, and other signs of compromise. Log reviews can be manual — where a security analyst inspects logs directly — or automated using specialized tools. Reviewing logs is a fundamental task for security and compliance, and is required by many standards such as ISO 27001, PCI-DSS, HIPAA, and NIST frameworks.

A **Security Information and Event Management (SIEM)** system is a platform designed to automatically collect, store, analyze, and correlate log data from multiple systems in real time. SIEM systems help detect security incidents much faster than manual log review, and they often trigger automated alerts if suspicious patterns are identified.

SIEMs aggregate logs from servers, firewalls, routers, IDS/IPS devices, cloud services, and endpoint security tools, then normalize the data into a consistent format. Once the data is centralized, the SIEM engine applies correlation rules, machine learning, or threat intelligence feeds to identify events that require immediate attention.

:bulb: Popular SIEM systems like Splunk, IBM QRadar, ArcSight, and Microsoft Sentinel allow security teams to automate detection, generate security dashboards, and assist with forensic analysis after incidents. SIEM platforms also play an essential role in compliance, helping produce audit-ready reports that demonstrate security event monitoring is active and effective.

**NetFlow** is a network protocol developed by Cisco that collects and records information about IP traffic flows traversing network interfaces. Unlike simple log files, which record discrete events, NetFlow data summarizes entire conversations between network endpoints. This makes it ideal for network visibility, capacity planning, anomaly detection, and forensic analysis.

NetFlow records include details like source IP, destination IP, source port, destination port, protocol type, packet count, byte count, and timestamps for flow start and end. This allows security teams to answer critical questions such as:
- Who is communicating with whom?
- When did the communication happen?
- How much data was transferred?
- Which protocols and ports were used?

When integrated with SIEM systems or log management platforms, NetFlow enhances situational awareness and helps detect threats like data exfiltration, port scanning, or lateral movement inside a compromised network.

**Log management** refers to the full lifecycle of log data: generation, collection, centralization, storage, analysis, retention, and secure disposal. Without proper log management, even the most advanced security tools will fail to deliver meaningful results because the raw data will be incomplete, inconsistent, or missing altogether.

A strong log management strategy includes:
- Defining which devices and systems must send logs.
- Securing log transmission (using encrypted channels).
- Centralizing logs in a secure repository.
- Structuring retention policies (how long logs must be kept).
- Implementing access control on log files.
- Regularly reviewing logs for anomalies.
- Automating alerting and analysis when possible.

:bulb: Modern log management systems like ELK Stack (Elasticsearch, Logstash, Kibana), Graylog, and cloud-native solutions like AWS CloudWatch or Azure Monitor help scale log collection and analysis, even for large or distributed systems.

### Open Questions ###

1. What is the primary goal of performing a log review in an organization?

<details> <summary>Show answer</summary> The primary goal of a log review is to systematically examine log files to detect abnormal patterns, unauthorized actions, misconfigurations, or security incidents early, before they escalate into larger problems. </details>

2. How does a SIEM system improve the efficiency of security monitoring compared to manual log reviews?

<details> <summary>Show answer</summary> A SIEM system improves security monitoring by automatically collecting, normalizing, analyzing, and correlating logs from multiple sources in real time, helping to detect incidents faster and triggering alerts when suspicious patterns are identified. </details>

3. What kind of network information does NetFlow provide that traditional log files might not capture?

<details> <summary>Show answer</summary> NetFlow provides detailed information about network traffic flows, including source and destination IP addresses, ports, protocols, data volume, and timestamps — helping security teams understand communication patterns, detect anomalies, and perform network forensics. </details>

4. Why is log management considered essential for both security monitoring and compliance?

<details> <summary>Show answer</summary> Log management ensures that log data is consistently collected, securely stored, properly retained, and regularly analyzed, which is critical for detecting security incidents, troubleshooting issues, and meeting compliance requirements such as ISO 27001, PCI-DSS, HIPAA, and NIST. </details>

5. List at least three best practices that should be included in a strong log management strategy.

<details> <summary>Show answer</summary> Best practices in log management include: securing log transmission, centralizing logs in a secure repository, applying retention policies, enforcing access controls on logs, and using automation for log review and anomaly detection. </details>

---

## 6.2.4 Synthetic transactions/benchmarks ##

A synthetic transaction is a testing technique used to check if a system, website, or application is working properly — even when no real users are currently using it. 

:brain: Synthetic transactions are fake or automated actions that simulate what a real person would do, like logging in, filling out a form, making a payment, or clicking a button.

These "fake" actions are created by developers or security teams and run automatically at regular times, or from different locations, to see if the system responds correctly. The goal is to spot problems before real users notice them and before security risks appear.

For example for an online banking website. A synthetic transaction could try to log in with a test account every five minutes. If the login page doesn’t load, or the response time is too slow, the monitoring system will send an alert so the technical team can check for issues — even if no customer has complained yet.

Besides checking performance, synthetic transactions are useful for cybersecurity too. They can help detect if something has gone wrong in the system due to a security problem, like:

- If a website has been defaced or hacked.
- If a login process is no longer working due to an attack.
- If a database is being blocked or slowed down by malicious traffic.
- If a service is "pretending" to be healthy, but the backend is actually broken or under attack.

By running synthetic transactions 24/7, an organization can notice unexpected changes in behavior that might be caused by security incidents. This helps reduce the time between when a problem happens and when it's detected (called Mean Time To Detect — MTTD).

Synthetic transactions are also helpful for:

- Baseline monitoring: knowing what "normal" looks like, so you can quickly spot abnormal activity.
- Testing under safe conditions: without needing real customers to be involved.
- Geographical coverage: you can run synthetic tests from different cities or countries to see if global users experience the same performance and security.

**Real User Monitoring (RUM)** is a different but equally important technique. While synthetic transactions simulate fake users, RUM tracks real users as they interact with your website, system, or application in real time.

Every time a real customer logs in, clicks, loads a page, or uses a service, RUM quietly collects data about their experience:

- Was the page fast or slow to load?
- Did any errors appear?
- Which part of the world is the user connecting from?
- What device or browser was the user using?

RUM helps organizations understand how real people are experiencing their system — not just under test conditions, but in day-to-day use, under real-world traffic and situations. This is valuable for both security and performance.

From a security perspective, RUM can:

1. Show unusual patterns, such as a single user making thousands of requests in a short time.
2. Detect suspicious activities like bots trying to scrape content or break into accounts.
3. Track usage spikes that might be caused by a Distributed Denial of Service (DDoS) attack.
4. Help identify whether errors are caused by user mistakes or possible security issues (such as broken authentication).

From a performance perspective, RUM is useful to:

- See if specific regions are experiencing slower service.
- Understand the impact of software updates on the user experience.
- Spot technical failures that only happen under real usage conditions.

Both synthetic transactions and real user monitoring serve different purposes but work best when used together:
| Feature / Aspect | Synthetic Transaction | RUM (Real User Monitoring) |
|------------------|-----------------------|----------------------------|
| Nature | Simulated, predictable tests | Real-world, live user data |
| Data source | Scripted interactions (simulated users) | Actual user sessions and events |
| Availability | Runs even when no users are online | Only runs when real users are active |
| Primary value | Early warning, uptime and security baselining | True user experience, performance and behaviour insights |
| Approach | Process-based, repeatable | Behaviour-based, uncontrolled/real-world |
| Environment | Controlled environment | Uncontrolled, real-world behaviour |

For example, a company could set up synthetic tests to alert the security team at night if the login service stops working — even if no user is active — while RUM could spot that a large number of users are having trouble logging in during business hours, perhaps because of an attack or bug.

### Open Questions ###

1. What is a synthetic transaction in cybersecurity testing?

<details> <summary>Show answer</summary> A synthetic transaction is a fake or automated action designed to simulate what a real user would do, like logging in or clicking a button, to check if a system is working properly — even when no real users are using it. </details>

2. Why do organizations use synthetic transactions?

<details> <summary>Show answer</summary> Organizations use synthetic transactions to detect problems or security issues early, before real users notice, and to continuously test systems for availability, performance, and abnormal behavior. </details>

3. Give an example of how synthetic transactions might be used for an online banking website.

<details> <summary>Show answer</summary> A synthetic transaction could automatically log in with a test account every five minutes. If the login fails or is too slow, the system alerts the technical team, even if no real customer has complained yet. </details>

4. Besides performance, what kind of issues can synthetic transactions help detect?

<details> <summary>Show answer</summary> Synthetic transactions can help detect security problems like website defacement, broken login processes caused by attacks, database issues, and services pretending to be healthy when the backend is actually broken or compromised. </details>

5. What is the benefit of running synthetic transactions 24/7?

<details> <summary>Show answer</summary> Running synthetic transactions continuously helps reduce the time it takes to detect problems (Mean Time To Detect — MTTD) and ensures systems are monitored even outside business hours. </details>

6. What is baseline monitoring, and how do synthetic transactions help with it?

<details> <summary>Show answer</summary> Baseline monitoring means understanding what "normal" system behavior looks like. Synthetic transactions help establish this baseline, so it's easier to spot unusual or potentially harmful activity later on. </details>

7. What does Real User Monitoring (RUM) do differently from synthetic transactions?

<details> <summary>Show answer</summary> RUM tracks the behavior and experience of actual users in real-time, recording things like page load speed, errors, and geographic location, rather than running automated test actions. </details>

8. How can RUM help detect potential security threats?

<details> <summary>Show answer</summary> RUM can spot unusual patterns, like one user sending thousands of requests, detect bot activity, monitor DDoS attacks, and help identify whether errors are caused by users or possible security breaches. </details>

9. Why is it useful to combine synthetic transactions with Real User Monitoring?

<details> <summary>Show answer</summary> Using both provides the best coverage: synthetic transactions catch issues even when no users are online, while RUM reveals how real users experience the system during actual use — making it easier to detect both performance and security problems. </details>

10. How do synthetic transactions and RUM complement each other in detecting login issues?

<details> <summary>Show answer</summary> Synthetic transactions can detect if the login system breaks at night when no users are active, while RUM can highlight login troubles during the day when many real users encounter the same issue, helping security teams catch both types of problems. </details>

---

## 6.2.5 Code review and testing ##

In cybersecurity, code review and testing are critical to catching vulnerabilities before attackers do. Whether you’re part of a secure development lifecycle (SDLC), auditing third-party code, or helping developers fix security issues, knowing how code gets reviewed and tested can help you spot weak points and suggest better defenses.

**Code review** is the process of manually or automatically checking source code for errors, weaknesses, or security vulnerabilities before the software is released. A code review is usually done by a peer or a team of experts and focuses on quality, readability, logic, and — of course — security

For cybersecurity professionals, code reviews are a chance to detect common security flaws like:
- Hardcoded credentials.
- SQL injection risks.
- Poor input validation.
- Insecure API usage.
- Misuse of crypto libraries.

**Manual code reviews** can spot logic flaws and misuse of security features that automated tools might miss. **Automated reviews** (using static analysis tools) are great for finding repetitive coding mistakes and enforcing secure coding standards.

A Fagan inspection is a structured, formal type of code review introduced by Michael Fagan in the 1970s. Unlike casual peer reviews, Fagan inspections follow a strict process with clear roles, steps, and documentation.
The inspection usually goes like this:

| Step              | Description                                        |
|-------------------|----------------------------------------------------|
| Planning          | The inspection team is selected, and the code is prepared. |
| Overview          | The author explains the design and logic to the reviewers. |
| Preparation       | Reviewers study the code individually.             |
| Inspection Meeting| Reviewers meet to discuss and document defects.    |
| Rework            | The author fixes the problems.                     |
| Follow-up         | Reviewers verify the fixes.                        |

:bulb: In security, Fagan Inspection is especially useful for catching design-level problems and enforcing accountability, since every step is documented and roles (author, moderator, reviewer) are clearly separated.

**Static testing** means reviewing code, configuration, or architecture without executing the program. This includes both human code reviews and automated static analysis tools.
Static testing is valuable because it can detect bugs and vulnerabilities early, even before the software runs. Common findings include buffer overflows, hardcoded secrets, weak cryptographic practices, and insecure input handling.
For cybersecurity, static testing is often the first line of defense — allowing secure-by-design principles to be enforced from the start.

**Dynamic testing**, unlike static testing, runs the application and observes how it behaves in real time. Dynamic testing looks for security vulnerabilities like:
- SQL Injection.
- Cross-site scripting (XSS).
- Authentication bypass.
- Memory corruption

Dynamic testing tools (DAST — Dynamic Application Security Testing) don’t need access to the source code. Instead, they interact with the running application, much like an attacker would, which makes them ideal for identifying vulnerabilities in the final deployed environment.
Dynamic testing can be automated (via tools like Burp Suite) or manual, where testers craft custom attack payloads based on the app’s responses.

In **black box testing**, the tester has no knowledge of the application’s internals. The goal is to assess the system from an outsider’s perspective — just like a real attacker would.
In security, black box testing is commonly used for: Penetration testing,  Vulnerability scanning,  system integration testing.

:bulb: Since the tester doesn't rely on code access, black box testing is great for finding issues in real-world scenarios, such as broken access control, insecure server configurations, and input validation flaws.

**White box testing** (sometimes called clear box or transparent testing) is the opposite of black box testing. Here the tester has full knowledge of the source code, architecture, and internal logic.
This allows for deep coverage of edge cases, like:
- Identification of hidden vulnerabilities (logic errors, unsafe code paths).
- Security testing of cryptographic implementations.
- Verification of input validation, error handling, and boundary conditions.
- White box testing is often combined with static analysis to ensure that both code and design are secure.

:necktie: The most secure systems use a combination of all these practices — with static and white box techniques catching issues during development, and dynamic and black box methods simulating real-world attacks before and after release.

### Open Questions ###

1. What is the main purpose of a code review in software development?  
<details>
  <summary>Show answer</summary>
The main purpose of a code review is to find mistakes, improve code quality, and catch potential security vulnerabilities before the software is released. It also helps enforce coding standards and share knowledge within the team.
</details>

2. How does a Fagan inspection differ from a casual code review?  
<details>
  <summary>Show answer</summary>
A Fagan inspection is a formal and structured process that involves planning, preparation, and follow-ups, unlike casual code reviews which are often more informal and flexible. Fagan inspections focus on defect prevention and documentation.
</details>

3. Why is static testing important for cybersecurity?  
<details>
  <summary>Show answer</summary>
Static testing helps identify security issues like hardcoded credentials, unsafe input handling, or insecure coding practices early in development. This allows teams to fix vulnerabilities before the software runs in production.
</details>

4. When in the development cycle is static testing usually performed?  
<details>
  <summary>Show answer</summary>
Static testing is usually performed during the coding and design phase, before the software is executed. This makes it cost-effective for catching problems early.
</details>

5. What is dynamic testing, and how does it help in finding vulnerabilities?  
<details>
  <summary>Show answer</summary>
Dynamic testing involves running the application and observing its behavior under real conditions. It helps detect runtime vulnerabilities like SQL injection, XSS, or logic flaws that static testing might miss.
</details>

6. What is the main difference between black box testing and white box testing?  
<details>
  <summary>Show answer</summary>
Black box testing tests an application from an external perspective, without knowing its internal code or logic. White box testing, on the other hand, uses full knowledge of the system's internal structure to guide testing.
</details>

7. Why is black box testing useful for security assessments?  
<details>
  <summary>Show answer</summary>
Black box testing is useful for simulating real-world attacker behavior, as it reveals how the application handles unexpected input and interaction. It’s commonly used in penetration testing.
</details>

8. How does white box testing help identify deeper vulnerabilities?  
<details>
  <summary>Show answer</summary>
White box testing allows testers to explore hidden code paths, internal logic, and security controls that wouldn’t be visible from the outside. This makes it ideal for finding deep logic errors and unsafe code.
</details>

9. Why is combining static and dynamic testing considered a best practice in security?  
<details>
  <summary>Show answer</summary>
Combining static and dynamic testing gives better security coverage, since static testing can catch coding flaws early and dynamic testing can reveal runtime issues under real-world conditions. Both approaches complement each other.
</details>

10. How can Fagan inspections help improve security and code quality?  
<details>
  <summary>Show answer</summary>
Fagan inspections improve security by forcing developers and reviewers to methodically analyze code, reducing the chance of missing logic errors or insecure patterns. The structured process also creates clear accountability and documentation.
</details>


## 6.2.6 Misuse case testing ##

A **use case** describes how a system is supposed to behave when everything is working as intended. In software design, a use case defines a specific interaction between a user (or another system) and the software.For example, for an online banking application, a use case might be:“A customer logs in, views their balance, and transfers money to another account.”

**Use case testing** is the process of turning these expected behaviors into test scenarios, and verifying whether the system responds correctly. This helps confirm that:
- Legitimate users can complete their tasks.
- The system produces the expected output.
- Security mechanisms like input validation or authentication don’t break normal operations.

:necktie: From a cybersecurity perspective, use case testing helps ensure security features don’t harm usability, and that security measures don’t block legitimate actions. This is important for real-world applications, where overprotective security can sometimes cause downtime or user frustration.

While use cases focus on “how things should work”, **misuse cases** focus on “how things could go wrong.” A misuse case is a scenario where an attacker (or malicious user) tries to abuse the system in unexpected or harmful ways. For example: “An attacker tries to bypass the login by using SQL injection in the username field.”

Misuse case testing is a mindset shift: you ask “what could an attacker do here?” rather than “what should a customer do?” You design test scenarios where the goal is not to confirm expected behavior, but to see if the system:
- Rejects invalid inputs.
- Detects or blocks malicious activities.
- Handles abuse gracefully (no crashes or data leaks).

For security professionals, misuse case testing is an important technique to think like an attacker. It can reveal gaps in validation, error handling, and authorization that normal functional testing wouldn’t catch.

**UML (Unified Modeling Language)** is a standardized way to visualize a system’s design and behavior using diagrams. UML is often used by developers and architects, but security experts can also benefit from it, especially when preparing threat models or designing security controls.

Some of the most useful UML diagrams for security work are:
- Use Case Diagrams — to map user interactions with the system.
- Misuse Case Diagrams — a simple extension of use case diagrams, where attackers (or “malicious actors”) are shown trying to subvert the system.
- Sequence Diagrams — to show the order of operations or messages exchanged between system components. This can highlight attack surfaces.
- Class Diagrams — to represent the structure of the system, including relationships between modules, classes, and components.

:necktie: Security isn’t just about scanning and patching — it’s about designing systems that are secure by default and by design. Use case testing ensures the system works as intended. Misuse case testing ensures the system handles attacks safely. UML helps you communicate both.

### Open Questions ###

1. What is the main goal of use case testing in cybersecurity?  
<details>
  <summary>Show answer</summary>
The main goal of use case testing is to make sure that a system works properly for legitimate users by verifying expected behaviors, such as successful logins, transactions, or data retrieval.
</details>

2. How does misuse case testing help security experts strengthen a system?  
<details>
  <summary>Show answer</summary>
Misuse case testing helps security experts identify how attackers could abuse the system by simulating malicious behaviors, such as inputting harmful data or trying to bypass security controls.
</details>

3. What is the difference between use case testing and misuse case testing?  
<details>
  <summary>Show answer</summary>
Use case testing checks if the system handles normal, expected user actions correctly, while misuse case testing focuses on how the system reacts to malicious or unexpected actions from attackers.
</details>

4. How can UML diagrams support security analysis in software development?  
<details>
  <summary>Show answer</summary>
UML diagrams help security teams visualize how a system is designed, including the flow of data, user interactions, and connections between components — making it easier to identify potential weak spots or attack paths.
</details>

5. Why is it helpful to perform both use case and misuse case testing during software testing?  
<details>
  <summary>Show answer</summary>
Performing both use case and misuse case testing ensures that a system not only works as intended for real users but is also prepared to defend against invalid, harmful, or unexpected actions from attackers.
</details>

---

## 6.2.7 Coverage Analysis ##

Testing isn’t just about “running some checks” ,  it’s about knowing how much of your code and logic has actually been tested. Test coverage tells you which parts of your code have been exercised by your test cases and which haven’t. The higher the coverage, the lower the chance that an untested part of your system could hide a security vulnerability.

Test coverage is especially important in security-focused development because attackers often exploit the “forgotten” or poorly tested paths in software logic. If a branch, condition, or function hasn’t been tested, no one can guarantee it will behave securely in production.

At its core, test coverage is calculated as:

**Test Coverage (%) = (Number of items tested / Total number of items) × 100**




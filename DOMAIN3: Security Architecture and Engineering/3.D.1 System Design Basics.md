## 3.D.1 System Design Basics ##

### How a Computer Runs Your Code ###

Let‚Äôs break down how the different parts of a computer work together to run your code.

At the most basic level, computers understand only 0s and 1s ‚Äî this is called binary. A bit is the smallest piece of data (it‚Äôs either a 0 or 1), and 8 bits make 1 byte. A byte can store something like the letter "A" or the number "5".

To store all this information, we use disk storage. It comes in two main types:

- HDD (Hard Disk Drive) ‚Äî slower but cheaper.

- SSD (Solid State Drive) ‚Äî much faster, but more expensive.

SSDs are great when speed matters. For example, an SSD can read data at around 500‚Äì3,500 MB/s, while an HDD only hits about 80‚Äì160 MB/s. Also, both types keep your data even when the power is off ‚Äî we call this non-volatile storage.

But when you're actively using apps or running code, the computer doesn't use the disk directly. Instead, it loads data into RAM (Random Access Memory). RAM is much faster than disk storage but is volatile, meaning it loses all data when you restart the computer.

Still not fast enough? That‚Äôs where cache memory comes in. Cache is even smaller and faster than RAM ‚Äî it sits very close to the CPU. It‚Äôs used to store the most frequently accessed data, so the CPU can grab it instantly without waiting.

Finally, we have the CPU (Central Processing Unit) ‚Äî this is the brain that runs your code. It fetches, decodes, and executes instructions. But remember: your code in Java or Python is not directly understood by the CPU. It first gets compiled into machine code ‚Äî that‚Äôs the 0s and 1s ‚Äî and then executed.

Holding it all together is the motherboard, which connects every component, letting them communicate.

### From Code to Live Application: How Modern Systems Work ###

Once your code is written and tested, it‚Äôs time to deploy it ‚Äî that means making it live and usable by people. This process has become super streamlined thanks to a concept called CI/CD:

*CI/CD Pipeline*
CI/CD stands for:

Continuous Integration: Automatically testing new code when it's pushed to the repo.

Continuous Deployment: Automatically sending that tested code to production (the live version).

With tools like GitHub Actions or Jenkins, your code can go from Git to the server without manual work.

*Serving Users at Scale*

When your app is live, it‚Äôs going to receive requests from users. Here's how we handle them efficiently:

- Load Balancers & Reverse Proxies (e.g., Nginx):
They sit in front of your servers and distribute incoming traffic, so one server doesn‚Äôt get overloaded.

- External Storage Servers:
Data isn‚Äôt always stored on the same machine that runs your app. Often, we use remote storage servers to handle that.

- Services Talking to Services:
Apps are often made of multiple services that talk to each other ‚Äî this is called microservices.

- Logging and Monitoring:
Tools like PM2 (for back end) or Sentry (for front end) track your app's health and catch bugs or errors.

- Alerts & Notifications:
If something breaks, developers get alerts (often in Slack). You might also notify users:

General: ‚ÄúSomething went wrong.‚Äù

Specific: ‚ÄúPayment failed.‚Äù

- Debugging & Fixing Bugs:
Devs check logs, try to replicate the issue in a safe testing environment, debug it, and then release a hotfix ‚Äî a quick patch to stabilize things.

```mermaid 
flowchart LR
  A[Code Pushed to Git Repo] --> B[CI/CD Pipeline]
  B --> C[Tests Run Automatically]
  C --> D[Deployment to Production Server]

  D --> E[User Sends Request]
  E --> F[Load Balancer e.g., Nginx]
  F --> G1[Server 1]
  F --> G2[Server 2]

  D --> H[Logging & Monitoring]
  H --> I[Alerting System]
  I --> J[Developer Notified via Slack]
  J --> K[Bug Fixed & Hotfix Deployed]
    classDef center fill:#ffffff,color:#000000,stroke:#000000,stroke-width:1px,font-weight:bold
    classDef node fill:#e0e0e0,color:#000000,stroke:#000000,stroke-width:1px
```

### What Makes a System Well-Designed? ###
When engineers talk about a ‚Äúgood‚Äù system, they don‚Äôt just mean it works. A good system is designed with the future and failure in mind.

Key Qualities of Good System Design:

-**Scalability.**
Can the system handle more users and data as it grows?

-**Maintainability.**
Will other developers be able to understand, fix, or improve it later?

-**Efficiency.**
Does it use memory, CPU, and bandwidth wisely?

-**Resilience.**
Will it still work when something fails? Can it recover?

*The 3 Core Actions in System Design*. At its heart, every system does 3 things:

- **Moves Data.**
Example: A user's request goes to a server. Data goes from one service to another.

- **Stores Data.**
Not just about picking a database ‚Äî it includes backups, how fast you can get data back, and how often it's accessed.

- **Transforms Data.**
Taking raw input and turning it into something meaningful (like calculating the total price in a shopping cart).


| Core Principle  | What It Means                              |
| --------------- | ------------------------------------------ |
| Scalability     | Grows with users/data without breaking     |
| Maintainability | Easy to fix, improve, and understand       |
| Efficiency      | Uses resources smartly                     |
| Resilience      | Stays strong when things go wrong          |
| Move Data       | Handles requests and communication         |
| Store Data      | Saves, retrieves, and backs up information |
| Transform Data  | Processes raw input into useful output     |

### The CAP Theorem (a.k.a. Brewer‚Äôs Theorem) ###

The CAP theorem helps us understand what trade-offs we have to make when building distributed systems (systems spread across multiple machines).

It says you can only have two of the following three at the same time:

- Consistency
All users see the same data at the same time.
Example: If you update your bank balance, every server shows the same new number instantly.

- Availability
The system is always up and ready to respond ‚Äî even during failure.
Example: An online store that always takes your order, no matter what‚Äôs happening behind the scenes.

- Partition Tolerance
The system keeps running even if part of the network can‚Äôt talk to the rest.
Example: Even if a server in Tokyo can‚Äôt reach one in New York, the system still works.

You can‚Äôt have all three. In the real world, you have to choose two based on your priorities.

### Is It Working? Measuring Availability and Reliability ###

Availability answers the question: ‚ÄúIs the system up and running when users need it?‚Äù

We usually express it as a percentage ‚Äî and in the industry, we aim for what‚Äôs called "five nines":

| Availability | Max Downtime / Year |
| ------------ | ------------------- |
| 99.9%        | \~8.76 hours        |
| 99.99%       | \~52.6 minutes      |
| 99.999%      | \~5.26 minutes      |

Even one more nine makes a big difference!

**SLOs vs SLAs**

SLO (Service Level Objective): Internal goals. Example: "We want 99.9% of web requests to respond in under 300ms."

SLA (Service Level Agreement): Promises made to customers. Example: "We guarantee 99.99% uptime. If not, you get a refund."

**Reliability, Fault Tolerance, and Redundancy**
To keep your system up, even when things go wrong, we use three key ideas:

| Term                | What It Means                                              |
| ------------------- | ---------------------------------------------------------- |
| **Reliability**     | The system behaves correctly and consistently.             |
| **Fault Tolerance** | The system **keeps working** when a component fails.       |
| **Redundancy**      | Having **backup systems** ready to take over if one fails. |

We plan for failure so that users never even notice it happened.

**Throughput vs Latency**
Two other important performance metrics:

| Metric         | Meaning                                                   | Measured As               |
| -------------- | --------------------------------------------------------- | ------------------------- |
| **Throughput** | How much data or how many requests the system can handle. | Requests/sec, Queries/sec |
| **Latency**    | How long a single request takes to process.               | Milliseconds              |


Optimizing one may hurt the other. For example:

Batch processing = üîº throughput, but üîº latency.

Real-time = üîΩ latency, but üîΩ throughput.

